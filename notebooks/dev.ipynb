{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f7af612-e71d-4dfc-a477-088a7f79c1b6",
   "metadata": {},
   "source": [
    "# Development Notebook for Cortical Crowding Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f43079",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8a076-56ce-45b0-950d-b70220b4d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neuropythy as ny\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.optimize\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import gmean\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ad992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpl.rcParams['font.family'] = 'Arial'\n",
    "mpl.rcParams['font.family'] = 'HelveticaNeue'\n",
    "mpl.rcParams['font.size'] = 10\n",
    "mpl.rcParams['font.weight'] = 'light'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "mpl.rcParams['figure.dpi'] = 576  # 72*8\n",
    "mpl.rcParams['hatch.color'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328aa4ac-48d3-46ba-8748-e8c287d3edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to be able to load in libraries that are in this repository's src directory,\n",
    "# so we add src to the system path:\n",
    "try:\n",
    "    import corticalcrodwing as cc\n",
    "except ModuleNotFoundError:\n",
    "    # This probably happens because the corticalcrowding library hasn't been\n",
    "    # installed yet; we can add the src directory to the path to work around\n",
    "    # this here.\n",
    "    sys.path.append('../src')\n",
    "    # Now we can import corticalcrowding from the src directory:\n",
    "    import corticalcrowding as cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a085564f",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The root path where data is stored:\n",
    "data_path = Path('/data/crowding')\n",
    "\n",
    "# The crowding data CSV file:\n",
    "crowding_data_filename = data_path / 'crowding_data_withID.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb702d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of subjects:\n",
    "sids_NYU = [\n",
    "    'sub-wlsubj070',\n",
    "    'sub-wlsubj114',\n",
    "    'sub-wlsubj121',\n",
    "    'sub-wlsubj135']\n",
    "\n",
    "# 36 is used\n",
    "sids_NEI = [ \n",
    "    'sub-wlsubj119',\n",
    "    'sub-wlsubj127',\n",
    "    'sub-wlsubj136',\n",
    "    'sub-wlsubj137',\n",
    "    'sub-wlsubj143',\n",
    "    'sub-wlsubj144',\n",
    "    'sub-wlsubj145',\n",
    "    'sub-wlsubj146',\n",
    "    'sub-wlsubj147',\n",
    "    'sub-wlsubj148',\n",
    "    'sub-wlsubj149',\n",
    "    'sub-wlsubj150',\n",
    "    'sub-wlsubj151',\n",
    "    'sub-wlsubj152',\n",
    "    'sub-wlsubj153',\n",
    "    'sub-wlsubj154',\n",
    "    'sub-wlsubj155',\n",
    "    'sub-wlsubj156',\n",
    "    'sub-wlsubj157',\n",
    "    'sub-wlsubj158',\n",
    "    'sub-wlsubj159',\n",
    "    'sub-wlsubj160',\n",
    "    'sub-wlsubj161',\n",
    "    'sub-wlsubj162',\n",
    "    'sub-wlsubj163',\n",
    "    'sub-wlsubj164',\n",
    "    'sub-wlsubj165',\n",
    "    'sub-wlsubj166',\n",
    "    'sub-wlsubj167',\n",
    "    'sub-wlsubj168',\n",
    "    'sub-wlsubj170',\n",
    "    'sub-wlsubj171',\n",
    "    'sub-wlsubj172',\n",
    "    'sub-wlsubj173',\n",
    "    'sub-wlsubj174',\n",
    "    'sub-wlsubj175',\n",
    "    'sub-wlsubj176']\n",
    "\n",
    "sids_orig = sids_NYU + sids_NEI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355c2085",
   "metadata": {},
   "source": [
    "## Crowding Distance Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "crowding_data = pd.read_csv(crowding_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9cbdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each subject has 1 crowding distance value at each eccentricity\n",
    "mean_cd = (\n",
    "    crowding_data\n",
    "    .groupby(['ID','RadialEccentricity'])\n",
    "    ['CrowdingDistance']\n",
    "    .apply(gmean)\n",
    "    .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_list = crowding_data['CrowdingDistance'].tolist()\n",
    "mean_cd_list = mean_cd['CrowdingDistance'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 dfs based on the eccentricities in the dataframe:\n",
    "crowding_eccens = np.unique(crowding_data['RadialEccentricity'])\n",
    "assert len(crowding_eccens) == 3\n",
    "(ecc_1, ecc_2, ecc_3) = crowding_eccens\n",
    "\n",
    "mean_1 = mean_cd[mean_cd['RadialEccentricity'] == ecc_1]\n",
    "n_1 = len(mean_1)\n",
    "m_1 = mean_1['CrowdingDistance'].mean()\n",
    "st_1 = mean_1['CrowdingDistance'].std()\n",
    "\n",
    "mean_2 = mean_cd[mean_cd['RadialEccentricity'] == ecc_2]\n",
    "n_2 = len(mean_2)\n",
    "m_2 = mean_2['CrowdingDistance'].mean()\n",
    "st_2 = mean_2['CrowdingDistance'].std()\n",
    "\n",
    "mean_3 = mean_cd[mean_cd['RadialEccentricity'] == ecc_3]\n",
    "n_3 = len(mean_3)\n",
    "m_3 = mean_3['CrowdingDistance'].mean()\n",
    "st_3 = mean_3['CrowdingDistance'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ecc = crowding_data['RadialEccentricity'].tolist()\n",
    "mean_x_ecc = mean_cd['RadialEccentricity'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The crowding distance function in terms of eccentricity function described\n",
    "# by Kurzawski et al. (2023):\n",
    "Kurzawski2023_cd = cc.crowding.Kurzawski2023_cd\n",
    "\n",
    "# Fit the b parameter using this function by minimizing log error.\n",
    "b, _ = curve_fit(cc.crowding.log_Kurzawski2023_cd, x_ecc, np.log10(cd_list), p0=0.15)\n",
    "b = b[0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21810d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values = [m_1, m_2, m_3]\n",
    "std_values = [st_1, st_2, st_3]\n",
    "sem_values = np.array([st_1, st_2, st_3]) / np.sqrt([n_1, n_2, n_3])\n",
    "eccentricities = [ecc_1, ecc_2, ecc_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559446f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the bouma factor\n",
    "[val / div for val, div in zip(mean_values, eccentricities)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd336fc2",
   "metadata": {},
   "source": [
    "### bootstrap on crowding distance fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bootstrap_samples = 10000\n",
    "x = np.linspace(0.5,11,1000)\n",
    "eccentricities = [2.5, 5, 10]\n",
    "\n",
    "sid_df = crowding_data['ID'].values\n",
    "x_ecc = np.array(x_ecc)\n",
    "cd = np.array(cd_list)\n",
    "\n",
    "bootstrapped = cc.crowding.bootstrap_fit(sid_df, x_ecc, cd, x, num_bootstrap_samples)\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval_cd = np.percentile(bootstrapped, [2.5, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4264cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.5, 3))\n",
    "\n",
    "# Fitted value without bootstrap\n",
    "plt.plot(x, (0.43 + x + 0.06*(x**2)) * b, 'k-', label='Fitted Crowding Distance')\n",
    "\n",
    "# Plot individual data\n",
    "plt.plot(mean_x_ecc, mean_cd_list, 'ko', alpha=0.1, label='Individual Crowding Distance')\n",
    "\n",
    "# Plot error bars\n",
    "plt.errorbar(eccentricities, mean_values, yerr=std_values, fmt='o', color='red', label='Mean ± Std')\n",
    "plt.fill_between(x, confidence_interval_cd[0], confidence_interval_cd[1], color='gray', alpha=0.3, label='95% Confidence Interval')\n",
    "\n",
    "plt.xlabel('Eccentricity [deg]')\n",
    "plt.ylabel('Crowding distance [deg]')\n",
    "\n",
    "plt.ylim(bottom=0.1)  # Set lower limit to 0.1 (10^-1)\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd0c570",
   "metadata": {},
   "source": [
    "## Fit Cortical Magnification using inverse superlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb4154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict(sid=[], h=[], label=[], g=[], h_param=[], q=[], loss=[])\n",
    "for sid in sids_orig:\n",
    "    print(sid)\n",
    "    for h in ['lh','rh']:\n",
    "        for lbl in [1,2,3,4]:\n",
    "            try:\n",
    "                r = cc.cmag.fit_cumarea(sid, h, lbl, params0=(5.05, 0.43, 0.06), method='Powell')\n",
    "            except Exception as e:\n",
    "                print(f\"  - Skipping {sid} {h} {lbl}: {repr(e)}\")\n",
    "                continue\n",
    "            df['sid'].append(sid)\n",
    "            df['h'].append(h)\n",
    "            df['label'].append(lbl)\n",
    "            df['g'].append(r.x[0])\n",
    "            df['h_param'].append(r.x[1])\n",
    "            df['q'].append(r.x[2])\n",
    "            df['loss'].append(r.fun)\n",
    "\n",
    "invsuplin_params = pd.DataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "invsuplin_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf712b7a",
   "metadata": {},
   "source": [
    "### normalize cumulative area curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac597862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_curve(curve, model_end):\n",
    "    return 100 * (curve - curve[0]) / (model_end - curve[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3526203",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = sids_orig[3]\n",
    "\n",
    "inv_fits = invsuplin_params[invsuplin_params['sid'] == sid]\n",
    "\n",
    "area_labels = {1: \"V1\", 2: \"V2\", 3: \"V3\", 4: \"hV4\"}\n",
    "area_colors = {1: \"black\", 2: \"red\", 3: \"blue\", 4: \"cyan\"}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 3), dpi=72*8, sharey=True)\n",
    "\n",
    "for j, hemi in enumerate(['lh', 'rh']):\n",
    "    ax = axs[j]\n",
    "\n",
    "    for lbl in [1, 2, 3, 4]:\n",
    "\n",
    "        # get model parameters \n",
    "        inv_row = inv_fits[\n",
    "            (inv_fits['label'] == lbl) &\n",
    "            (inv_fits['h'] == hemi)\n",
    "        ]\n",
    "        if len(inv_row) == 0:\n",
    "            continue\n",
    "      \n",
    "        g = inv_row['g'].values[0]\n",
    "        h_param = inv_row['h_param'].values[0]  \n",
    "        q = inv_row['q'].values[0]\n",
    "\n",
    "        # get cumulative area\n",
    "        ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "        if ecc is None or len(ecc) == 0:\n",
    "            continue\n",
    "\n",
    "        ii = np.argsort(ecc)\n",
    "        ecc = ecc[ii]\n",
    "        srf = srf[ii]\n",
    "        cum_area = np.cumsum(srf)\n",
    "\n",
    "        cumfit = cc.cmag.invsuplin_integral(\n",
    "            ecc,\n",
    "            g=g,\n",
    "            h=h_param,\n",
    "            q=q,\n",
    "            tol=1e-4,\n",
    "        )\n",
    "\n",
    "        # normalize model curve\n",
    "        cumfit_norm = norm_curve(cumfit, cumfit[-1])\n",
    "\n",
    "        ax.plot(\n",
    "            ecc, cumfit_norm,\n",
    "            lw=2,\n",
    "            color=area_colors[lbl],\n",
    "            label=area_labels[lbl]\n",
    "        )\n",
    "\n",
    "    ax.set_title(hemi.upper())\n",
    "    ax.set_xlabel(\"Eccentricity [deg]\")\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "axs[0].set_ylabel(\"Normalized cumulative area [%]\")\n",
    "\n",
    "# legend only on right panel \n",
    "# axs[1].legend(title=\"Area\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe88c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model curver together with data\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 3), dpi=72*8, sharey=True)\n",
    "\n",
    "for j, hemi in enumerate([\"lh\", \"rh\"]):\n",
    "    ax = axs[j]\n",
    "\n",
    "    for lbl in [1, 2, 3, 4]:\n",
    "\n",
    "        inv_row = inv_fits[\n",
    "            (inv_fits[\"label\"] == lbl) &\n",
    "            (inv_fits[\"h\"] == hemi)\n",
    "        ]\n",
    "        if len(inv_row) == 0:\n",
    "            continue\n",
    "\n",
    "        g = inv_row[\"g\"].values[0]\n",
    "        h_param = inv_row[\"h_param\"].values[0]\n",
    "        q = inv_row[\"q\"].values[0]\n",
    "\n",
    "        ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "        if ecc is None or len(ecc) == 0:\n",
    "            continue\n",
    "\n",
    "        ii = np.argsort(ecc)\n",
    "        ecc = ecc[ii]\n",
    "        srf = srf[ii]\n",
    "        cum_area = np.cumsum(srf)\n",
    "\n",
    "        # model prediction\n",
    "        cumfit = cc.cmag.invsuplin_integral(\n",
    "            ecc,\n",
    "            g=g,\n",
    "            h=h_param,\n",
    "            q=q,\n",
    "            tol=1e-4,\n",
    "        )\n",
    "\n",
    "        # normalization \n",
    "        model_end = cumfit[-1]\n",
    "\n",
    "        cumfit_norm   = norm_curve(cumfit,   model_end)\n",
    "        cum_area_norm = norm_curve(cum_area, model_end)\n",
    "\n",
    "        color = area_colors[lbl]\n",
    "\n",
    "        # Model = solid\n",
    "        ax.plot(\n",
    "            ecc,\n",
    "            cumfit_norm,\n",
    "            color=color,\n",
    "            lw=2,\n",
    "            label=area_labels[lbl] if j == 1 else None,\n",
    "        )\n",
    "\n",
    "        # Empirical data = dashed\n",
    "        ax.plot(\n",
    "            ecc,\n",
    "            cum_area_norm,\n",
    "            color=color,\n",
    "            lw=1.2,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Eccentricity [deg]\")\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_title(hemi.upper())\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "axs[0].set_ylabel(\"Normalized cumulative area [%]\")\n",
    "axs[1].legend(title=\"Map\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370dae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_params = invsuplin_params.groupby('label')[['g', 'h_param','q']].mean().reset_index()\n",
    "mean_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8530fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_params = invsuplin_params.groupby('label')[['g', 'h_param','q']].median().reset_index()\n",
    "median_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ce330",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_labels = {1: \"V1\", 2: \"V2\", 3: \"V3\", 4: \"hV4\"}\n",
    "area_colors = {1: \"black\", 2: \"red\", 3: \"blue\", 4: \"cyan\"}\n",
    "\n",
    "ecc = np.linspace(0, 12, 500)  \n",
    "\n",
    "def plot_group_model(params_df, title):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3.5, 3), dpi=72*8)\n",
    "\n",
    "    for _, row in params_df.iterrows():\n",
    "        lbl     = int(row['label'])\n",
    "        g       = row['g']\n",
    "        h_param = row['h_param']\n",
    "        q       = row['q']\n",
    "\n",
    "        # model cumulative area from invsuplin\n",
    "        cumfit = cc.cmag.invsuplin_integral(\n",
    "            ecc,\n",
    "            g=g,\n",
    "            h=h_param,\n",
    "            q=q,\n",
    "            tol=1e-4,\n",
    "        )\n",
    "\n",
    "        # normalize \n",
    "        cumfit_norm = norm_curve(cumfit, cumfit[-1])   \n",
    "\n",
    "        ax.plot(\n",
    "            ecc, cumfit_norm,\n",
    "            lw=2,\n",
    "            color=area_colors[lbl],\n",
    "            label=area_labels[lbl]\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Eccentricity [deg]\")\n",
    "    ax.set_ylabel(\"Normalized cumulative area [%]\")\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend(title=\"Maps\", fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot using mean parameters \n",
    "plot_group_model(mean_params, \"Average model fit using mean parameters\")\n",
    "\n",
    "# Plot using median parameters\n",
    "plot_group_model(median_params, \"Average model fit using median parameters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839321a0",
   "metadata": {},
   "source": [
    "### check r square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c511615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rsquared(pred, gold):\n",
    "    var_gold = np.var(gold)\n",
    "    error = gold - pred\n",
    "    mean_sse = np.mean(error**2)\n",
    "    return 1 - mean_sse / var_gold if var_gold > 0 else np.nan\n",
    "\n",
    "\n",
    "r2_values = []\n",
    "\n",
    "for idx, row in invsuplin_params.iterrows():\n",
    "    sid   = row['sid']\n",
    "    hemi  = row['h']\n",
    "    lbl   = row['label']\n",
    "\n",
    "    g = row['g']\n",
    "    h = row['h_param']\n",
    "    q = row['q']\n",
    "\n",
    "    ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "    if ecc is None or len(ecc) == 0:\n",
    "        r2_values.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    ii = np.argsort(ecc)\n",
    "    ecc = ecc[ii]\n",
    "    srf = srf[ii]\n",
    "\n",
    "    # empirical cumulative area\n",
    "    cum_emp = np.cumsum(srf)\n",
    "\n",
    "    # model cumulative area\n",
    "    cum_fit = cc.cmag.invsuplin_integral(ecc, g=g, h=h, q=q)\n",
    "    cum_fit = np.real_if_close(cum_fit)\n",
    "\n",
    "    r2 = model_rsquared(cum_fit, cum_emp)\n",
    "    r2_values.append(r2)\n",
    "\n",
    "\n",
    "invsuplin_params['rsq'] = r2_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616408b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas  = ['V1', 'V2', 'V3', 'hV4']\n",
    "labels = [1, 2, 3, 4]\n",
    "\n",
    "mean_r2_inv = []\n",
    "sem_r2_inv  = []\n",
    "all_r2_inv  = []\n",
    "\n",
    "for lbl in labels:\n",
    "    r2_vals = invsuplin_params[invsuplin_params['label'] == lbl]['rsq'].values\n",
    "    r2_vals = r2_vals[np.isfinite(r2_vals)]\n",
    "\n",
    "    all_r2_inv.append(r2_vals)\n",
    "    mean_r2_inv.append(np.mean(r2_vals))\n",
    "    sem_r2_inv.append(np.std(r2_vals) / np.sqrt(len(r2_vals)))\n",
    "\n",
    "mean_r2_inv = np.array(mean_r2_inv)\n",
    "sem_r2_inv  = np.array(sem_r2_inv)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5, 3.5), dpi=72*8)\n",
    "\n",
    "x = np.arange(len(areas))\n",
    "\n",
    "for i in range(len(areas)):\n",
    "    r2 = all_r2_inv[i]\n",
    "    ax.scatter(np.full_like(r2, x[i]), r2,\n",
    "               color='lightblue', alpha=0.5, s=20,\n",
    "               label='Individual R²' if i == 0 else None)\n",
    "\n",
    "ax.errorbar(x, mean_r2_inv, yerr=sem_r2_inv, fmt='o',\n",
    "            capsize=4, linewidth=1.5, markersize=6,\n",
    "            color='navy', label='Mean ± SEM')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(areas)\n",
    "ax.set_ylabel('R²')\n",
    "ax.set_title('Inverse-superlinear model R²')\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check crowding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricities = np.array([2.5, 5, 10])\n",
    "\n",
    "gold = np.array(mean_values)\n",
    "\n",
    "# model predictions at the same 3 eccentricities\n",
    "pred = (0.43 + eccentricities + 0.06 * (eccentricities**2)) * b\n",
    "\n",
    "r2 = model_rsquared(pred, gold)\n",
    "print(\"R² =\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all subject-level crowding distance\n",
    "gold = np.array(cd_list)           \n",
    "\n",
    "# x_ecc = ecc for each measurement (same length as cd_list)\n",
    "x_ecc = np.array(x_ecc)\n",
    "\n",
    "# model prediction at each of those data eccentricities\n",
    "pred = (0.43 + x_ecc + 0.06 * (x_ecc**2)) * b\n",
    "\n",
    "r2_all = model_rsquared(pred, gold)\n",
    "print(\"R² across all subject-level data:\", r2_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3260a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "709efe9a",
   "metadata": {},
   "source": [
    "## bootstrap on cortical magnification curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3235ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap on curve\n",
    "num_bootstrap_samples = 10000\n",
    "x = np.linspace(0.5, 11, 1000)\n",
    "\n",
    "bootstrap_cmag_per_label = {}\n",
    "group_curve_per_label = {}\n",
    "\n",
    "for lbl in [1, 2, 3, 4]:\n",
    "    df_lbl = invsuplin_params[invsuplin_params['label'] == lbl]\n",
    "    \n",
    "    # one curve per subject, averaged across hemispheres\n",
    "    subj_curves = []\n",
    "    for sid, df_sub in df_lbl.groupby('sid'):\n",
    "        g_sub  = df_sub['g'].mean()\n",
    "        h_sub  = df_sub['h_param'].mean()\n",
    "        q_sub  = df_sub['q'].mean()\n",
    "\n",
    "        curve = cc.cmag.invsuplin(x, g=g_sub, h=h_sub, q=q_sub)\n",
    "        subj_curves.append(curve)\n",
    "\n",
    "    subj_curves = np.array(subj_curves) \n",
    "    n_subj = subj_curves.shape[0]   # 40 here\n",
    "    \n",
    "    group_curve = np.mean(subj_curves, axis=0)\n",
    "    group_curve_per_label[lbl] = group_curve\n",
    "\n",
    "    # bootstrap the mean curve\n",
    "    boot_curves = []\n",
    "    for _ in range(num_bootstrap_samples):\n",
    "        idx = np.random.choice(n_subj, size=n_subj, replace=True)\n",
    "        boot_curve = np.mean(subj_curves[idx, :], axis=0)\n",
    "        boot_curves.append(boot_curve)\n",
    "\n",
    "    bootstrap_cmag_per_label[lbl] = np.array(boot_curves)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40cc146",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_v1 = bootstrap_cmag_per_label[1]\n",
    "bootstrapped_v2 = bootstrap_cmag_per_label[2]\n",
    "bootstrapped_v3 = bootstrap_cmag_per_label[3]\n",
    "bootstrapped_v4 = bootstrap_cmag_per_label[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_v1 = np.percentile(bootstrapped_v1, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v2 = np.percentile(bootstrapped_v2, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v3 = np.percentile(bootstrapped_v3, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v4 = np.percentile(bootstrapped_v4, [2.5, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3870c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 11, 1000)\n",
    "fig, ax = plt.subplots(1,1, figsize=(3.5, 3.5), dpi=72*8)\n",
    "\n",
    "ref_curve = 17.3 / (x + 0.75)\n",
    "ax.plot(x, ref_curve, '--', color='gray', linewidth=2, label='1D HH')\n",
    "\n",
    "# plot 1d cmag\n",
    "ax.plot(x, np.sqrt(group_curve_per_label[1]),  color='black', label='V1 fitted')\n",
    "ax.plot(x, np.sqrt(group_curve_per_label[2]),  color='red',   label='V2 fitted')\n",
    "ax.plot(x, np.sqrt(group_curve_per_label[3]),  color='blue',  label='V3 fitted') \n",
    "ax.plot(x, np.sqrt(group_curve_per_label[4]),  color='cyan',  label='hV4 fitted')\n",
    "\n",
    "ax.fill_between(x, np.sqrt(confidence_interval_v1[0]),\n",
    "                   np.sqrt(confidence_interval_v1[1]),\n",
    "                color='black', alpha=0.3)\n",
    "ax.fill_between(x, np.sqrt(confidence_interval_v2[0]),\n",
    "                   np.sqrt(confidence_interval_v2[1]),\n",
    "                color='red', alpha=0.3)\n",
    "ax.fill_between(x, np.sqrt(confidence_interval_v3[0]),\n",
    "                   np.sqrt(confidence_interval_v3[1]),\n",
    "                color='blue', alpha=0.3)\n",
    "ax.fill_between(x, np.sqrt(confidence_interval_v4[0]),\n",
    "                   np.sqrt(confidence_interval_v4[1]),\n",
    "                color='cyan', alpha=0.3)\n",
    "\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Eccentricity [deg]\")\n",
    "ax.set_ylabel(\"1D Cortical Magnification [mm/deg]\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd6dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 11, 1000)\n",
    "bootstrapped_ccd_1 = []\n",
    "bootstrapped_ccd_2 = []\n",
    "bootstrapped_ccd_3 = []\n",
    "bootstrapped_ccd_4 = []\n",
    "\n",
    "# Iterate through 10000 bootstrapped samples\n",
    "for i in range(10000):\n",
    "    ccd_v1 = bootstrapped[i] * np.sqrt(bootstrapped_v1[i])\n",
    "    bootstrapped_ccd_1.append(ccd_v1)\n",
    "    \n",
    "    ccd_v2 = bootstrapped[i] * np.sqrt(bootstrapped_v2[i])\n",
    "    bootstrapped_ccd_2.append(ccd_v2)\n",
    "    \n",
    "    ccd_v3 = bootstrapped[i] * np.sqrt(bootstrapped_v3[i])\n",
    "    bootstrapped_ccd_3.append(ccd_v3)\n",
    "    \n",
    "    ccd_v4 = bootstrapped[i] * np.sqrt(bootstrapped_v4[i])\n",
    "    bootstrapped_ccd_4.append(ccd_v4)\n",
    "\n",
    "bootstrapped_ccd_1 = np.array(bootstrapped_ccd_1)\n",
    "bootstrapped_ccd_2 = np.array(bootstrapped_ccd_2)\n",
    "bootstrapped_ccd_3 = np.array(bootstrapped_ccd_3)\n",
    "bootstrapped_ccd_4 = np.array(bootstrapped_ccd_4)\n",
    "\n",
    "# Calculate the mean of bootstrapped CCD values for each visual area\n",
    "ccd1 = np.mean(bootstrapped_ccd_1, axis=0)\n",
    "ccd2 = np.mean(bootstrapped_ccd_2, axis=0)\n",
    "ccd3 = np.mean(bootstrapped_ccd_3, axis=0)\n",
    "ccd4 = np.mean(bootstrapped_ccd_4, axis=0)\n",
    "\n",
    "# Calculate the confidence interval for bootstrapped CCD values for each visual area\n",
    "confidence_interval_ccd_1 = np.percentile(bootstrapped_ccd_1,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_2 = np.percentile(bootstrapped_ccd_2,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_3 = np.percentile(bootstrapped_ccd_3,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_4 = np.percentile(bootstrapped_ccd_4,  [16, 84], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da861a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coefficient of variation for ccd_1\n",
    "mean_ccd_1 = np.mean(ccd1)\n",
    "std_ccd_1 = np.std(ccd1)\n",
    "cv_ccd_1 = std_ccd_1 / mean_ccd_1\n",
    "rounded_cv_ccd_1 = round(cv_ccd_1, 3)\n",
    "\n",
    "print(\"Coefficient of Variation (CCD 1):\", rounded_cv_ccd_1)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_2\n",
    "mean_ccd_2 = np.mean(ccd2)\n",
    "std_ccd_2 = np.std(ccd2)\n",
    "cv_ccd_2 = std_ccd_2 / mean_ccd_2\n",
    "rounded_cv_ccd_2 = round(cv_ccd_2, 3)\n",
    "print(\"Coefficient of Variation (CCD 2):\", rounded_cv_ccd_2)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_3\n",
    "mean_ccd_3 = np.mean(ccd3)\n",
    "std_ccd_3 = np.std(ccd3)\n",
    "cv_ccd_3 = std_ccd_3 / mean_ccd_3\n",
    "rounded_cv_ccd_3 = round(cv_ccd_3, 3)\n",
    "print(\"Coefficient of Variation (CCD 3):\", rounded_cv_ccd_3)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_4\n",
    "mean_ccd_4 = np.mean(ccd4)\n",
    "std_ccd_4 = np.std(ccd4)\n",
    "cv_ccd_4 = std_ccd_4 / mean_ccd_4\n",
    "rounded_cv_ccd_4 = round(cv_ccd_4, 3)\n",
    "print(\"Coefficient of Variation (CCD 4):\", rounded_cv_ccd_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6fb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_ccd_1, mean_ccd_2, mean_ccd_3, mean_ccd_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e71bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_cv_1 = cc.corticalcrowding.bootstrap_cv(ccd1)\n",
    "ci_1 = np.percentile(bootstrapped_cv_1, [2.5, 97.5])\n",
    "\n",
    "bootstrapped_cv_2 = cc.corticalcrowding.bootstrap_cv(ccd2)\n",
    "ci_2 = np.percentile(bootstrapped_cv_2, [2.5, 97.5])\n",
    "\n",
    "bootstrapped_cv_3 = cc.corticalcrowding.bootstrap_cv(ccd3)\n",
    "ci_3 = np.percentile(bootstrapped_cv_3, [2.5, 97.5])\n",
    "\n",
    "bootstrapped_cv_4 = cc.corticalcrowding.bootstrap_cv(ccd4)\n",
    "ci_4 = np.percentile(bootstrapped_cv_4, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0955c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ccd_values = [cv_ccd_1, cv_ccd_2, cv_ccd_3, cv_ccd_4]\n",
    "ccd_labels = ['V1', 'V2', 'V3', 'hV4']\n",
    "cv_ci_list = [(ci_1[0], ci_1[1]), (ci_2[0], ci_2[1]), (ci_3[0], ci_3[1]),(ci_4[0], ci_4[1])]\n",
    "\n",
    "lower_bound = [ci[0] for ci in cv_ci_list]\n",
    "upper_bound = [ci[1] for ci in cv_ci_list]\n",
    "\n",
    "yerr = [[cv_ccd_values[i] - lower_bound[i] for i in range(len(cv_ccd_values))],\n",
    "        [upper_bound[i] - cv_ccd_values[i] for i in range(len(cv_ccd_values))]]\n",
    "\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.bar(ccd_labels, cv_ccd_values, yerr=yerr, capsize=5, color=['gray', 'red', 'blue', 'cyan'])\n",
    "\n",
    "#plt.xlabel('Visual Areas')\n",
    "plt.ylabel('Coefficient of Variation')\n",
    "#plt.title('Coefficient of Variation for Cortical Crowding Distance')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ab7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean cortical crowding distance of each area\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.plot(x, ccd1, label='Cortical crowding distance in V1', color='black')\n",
    "plt.plot(x, ccd2, label='Cortical crowding distance in V2', color='red')\n",
    "plt.plot(x, ccd3, label='Cortical crowding distance in V3', color='blue')\n",
    "plt.plot(x, ccd4, label='Cortical crowding distance in hV4', color='cyan')\n",
    "\n",
    "plt.fill_between(x, confidence_interval_ccd_1[0], confidence_interval_ccd_1[1], color='black', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_2[0], confidence_interval_ccd_2[1], color='red', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_3[0], confidence_interval_ccd_3[1], color='blue', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_4[0], confidence_interval_ccd_4[1], color='cyan', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.xlabel('Eccentricity [deg]')\n",
    "plt.ylabel('Cortical Crowding Distance [mm]')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.plot(x, ccd1/ccd1[0], color='black')\n",
    "plt.plot(x, ccd2/ccd2[0], color='red')\n",
    "plt.plot(x, ccd3/ccd3[0], color='blue')\n",
    "plt.plot(x, ccd4/ccd4[0], color='cyan')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.xlabel('Eccentricity [deg]')\n",
    "plt.ylabel('Normalized Cortical C.D. [mm]')\n",
    "#plt.xticks([2.5, 5, 10])\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34715f6",
   "metadata": {},
   "source": [
    "## use 1d visual magnification to predict crowidng distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "invsuplin_params_bi = invsuplin_params.groupby(\n",
    "    ['sid', 'label'], as_index=False\n",
    "    ).agg({\n",
    "    'g': 'mean',\n",
    "    'h_param': 'mean',\n",
    "    'q': 'mean',\n",
    "    'loss': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30de18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = invsuplin_params_bi.merge(\n",
    "    pd.DataFrame(dict(RadialEccentricity=[2.5, 5.0, 10.0])),\n",
    "    how='cross'\n",
    ")\n",
    "\n",
    "g   = df_mean['g'].to_numpy()\n",
    "h   = df_mean['h_param'].to_numpy()\n",
    "q   = df_mean['q'].to_numpy()\n",
    "ecc = df_mean['RadialEccentricity'].to_numpy()\n",
    "\n",
    "# df_mean['cmag_fit'] = (g / (h + ecc + q * ecc**2))**2\n",
    "# df_mean['cmag_rad_fit'] = np.sqrt(df_mean['cmag_fit'] / 2.0)\n",
    "# df_mean['vmag_rad_fit'] = 1.0 / df_mean['cmag_rad_fit']\n",
    "\n",
    "df_mean['cmag_fit'] = (g / (h + ecc + q * ecc**2))**2\n",
    "df_mean['cmag_1d_fit'] = np.sqrt(df_mean['cmag_fit'])\n",
    "df_mean['vmag_1d_fit'] = 1.0 / df_mean['cmag_1d_fit']\n",
    "\n",
    "# merge in mean crowding distance\n",
    "mean_cd = mean_cd.rename(columns={\"ID\": \"sid\"})\n",
    "df_mean = df_mean.merge(mean_cd, on=['sid', 'RadialEccentricity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e783ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002db219",
   "metadata": {},
   "outputs": [],
   "source": [
    "res    = {1: [], 2: [], 3: [], 4: []}\n",
    "slopes = {1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "for subject, subject_data in df_mean.groupby(['sid']):\n",
    "    for lbl in [1, 2, 3, 4]:\n",
    "\n",
    "        ssdf = subject_data[subject_data['label'] == lbl]\n",
    "        if ssdf.empty:\n",
    "            continue\n",
    "\n",
    "        x = ssdf['vmag_1d_fit'].values\n",
    "        y = ssdf['CrowdingDistance'].values\n",
    "        rss, slope = cc.regression.fit_and_evaluate(x,y)\n",
    "\n",
    "        res[lbl].append(rss)\n",
    "        slopes[lbl].append(slope)\n",
    "\n",
    "\n",
    "mean_rss = [np.mean(res[l]) for l in [1, 2, 3, 4]]\n",
    "std_rss  = [np.std(res[l])  for l in [1, 2, 3, 4]]\n",
    "\n",
    "n_subjects = len(df_mean['sid'].unique())\n",
    "sem_rss = np.array(std_rss) / np.sqrt(n_subjects)\n",
    "\n",
    "print(\"Mean RSS:\", mean_rss)\n",
    "print(\"SEM RSS:\", sem_rss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['V1', 'V2', 'V3', 'hV4']\n",
    "colors = ['grey', 'red', 'blue', 'cyan'] \n",
    "\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.bar(labels, mean_rss, yerr=sem_rss, color=colors, capsize=6)\n",
    "\n",
    "plt.ylabel(\"Residual Sum of Squares [deg²]\")\n",
    "plt.title(\"Mean Residual Sum of Squares Across Visual Areas\")\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['V1', 'V2', 'V3', 'hV4']\n",
    "colors = ['grey', 'red', 'blue', 'cyan'] \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5, 3))\n",
    "\n",
    "ax.bar(labels, mean_rss, yerr=sem_rss, color=colors, capsize=6, alpha=0.6)\n",
    "\n",
    "x_positions = np.arange(4)  \n",
    "\n",
    "for i, lbl in enumerate([1, 2, 3, 4]):\n",
    "    y_vals = res[lbl]                 \n",
    "    jitter = (np.random.rand(len(y_vals)) - 0.5) * 0.15  # small horizontal jitter\n",
    "    ax.scatter(np.full(len(y_vals), x_positions[i]) + jitter,\n",
    "               y_vals,\n",
    "               s=20, \n",
    "               color='black',\n",
    "               alpha=0.7,\n",
    "               zorder=10)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"Residual Sum of Squares [deg²]\")\n",
    "ax.set_title(\"Mean Residual Sum of Squares Across Visual Areas\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3982766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of parameters\n",
    "area_names = {1: \"V1\", 2: \"V2\", 3: \"V3\", 4: \"hV4\"}\n",
    "\n",
    "fig, axs = plt.subplots(4, 3, figsize=(9, 8), sharex='col')\n",
    "params = ['g', 'h_param', 'q']\n",
    "\n",
    "for i, lbl in enumerate([1, 2, 3, 4]):\n",
    "    df_lbl = invsuplin_params[invsuplin_params['label'] == lbl]\n",
    "    for j, param in enumerate(params):\n",
    "        ax = axs[i, j]\n",
    "        vals = df_lbl[param].values\n",
    "        vals = vals[np.isfinite(vals)]\n",
    "\n",
    "        ax.hist(vals, bins=20, alpha=0.7)\n",
    "        if i == 0:\n",
    "            ax.set_title(param)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(area_names[lbl])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d1520",
   "metadata": {},
   "source": [
    "## quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# save directory\n",
    "save_dir = os.path.expanduser('~/for_crowding_figures_inv_sup_12.5')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for sid in sids_orig:\n",
    "\n",
    "    # inverse-superlinear params for this subject\n",
    "    inv_fits = invsuplin_params[invsuplin_params['sid'] == sid]\n",
    "\n",
    "    fig, axs = plt.subplots(4, 2, figsize=(7, 7), dpi=72*8,\n",
    "                            sharex=True, sharey=True)\n",
    "\n",
    "    for i, lbl in enumerate([1, 2, 3, 4]):   \n",
    "        for j, hemi in enumerate(['lh', 'rh']):\n",
    "            ax = axs[i, j]\n",
    "\n",
    "            inv_row = inv_fits[\n",
    "                (inv_fits['label'] == lbl) &\n",
    "                (inv_fits['h'] == hemi)\n",
    "            ]\n",
    "            if len(inv_row) == 0:\n",
    "                continue\n",
    "\n",
    "            g = inv_row['g'].values[0]\n",
    "            h_param = inv_row['h_param'].values[0]    \n",
    "            q = inv_row['q'].values[0]\n",
    "\n",
    "            # empirical cumulative area\n",
    "            ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "            if ecc is None or len(ecc) == 0:\n",
    "                continue\n",
    "\n",
    "            ii = np.argsort(ecc)\n",
    "            ecc = ecc[ii]\n",
    "            srf = srf[ii]\n",
    "            cum_area = np.cumsum(srf)\n",
    "\n",
    "            # cumulative area fit from inverse-superlinear model\n",
    "            cumarea_fit = cc.cmag.invsuplin_integral(\n",
    "                ecc,\n",
    "                g=g,\n",
    "                h=h_param,\n",
    "                q=q,\n",
    "                tol=1e-4\n",
    "            )\n",
    "\n",
    "            # plot model and empirical cumulative area\n",
    "            ax.plot(ecc, cumarea_fit / 100, color='blue', label=\"Best Fit Model\")\n",
    "            ax.plot(ecc, cum_area    / 100, color='gray', label=\"Cumulative Surface Area\")\n",
    "\n",
    "            ax.set_ylabel(r\"Surface Area [cm$^2$]\")\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "    axs[0, 1].legend()\n",
    "    axs[3, 0].set_xlabel(\"Eccentricity [deg]\")\n",
    "    axs[3, 1].set_xlabel(\"Eccentricity [deg]\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save figure for this subject\n",
    "    fig_path = os.path.join(save_dir, f\"fits_qc_{sid}.png\")\n",
    "    fig.savefig(fig_path, dpi=300)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = sids_orig[3]\n",
    "\n",
    "inv_fits = invsuplin_params[invsuplin_params['sid'] == sid]\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(7, 7), dpi=72*8,\n",
    "                        sharex=True, sharey=True)\n",
    "\n",
    "for i, lbl in enumerate([1, 2, 3, 4]): \n",
    "    for j, hemi in enumerate(['lh', 'rh']):\n",
    "        ax = axs[i, j]\n",
    "\n",
    "        inv_row = inv_fits[\n",
    "            (inv_fits['label'] == lbl) &\n",
    "            (inv_fits['h'] == hemi)\n",
    "        ]\n",
    "        if len(inv_row) == 0:\n",
    "            continue\n",
    "\n",
    "        g = inv_row['g'].values[0]\n",
    "        h_param = inv_row['h_param'].values[0]  \n",
    "        q = inv_row['q'].values[0]\n",
    "\n",
    "        # load empirical surface area\n",
    "        ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "        if ecc is None or len(ecc) == 0:\n",
    "            continue\n",
    "\n",
    "        ii = np.argsort(ecc)\n",
    "        ecc = ecc[ii]\n",
    "        srf = srf[ii]\n",
    "        cum_area = np.cumsum(srf)\n",
    "\n",
    "        # cumulative area from inverse-superlinear model\n",
    "        cumarea_fit = cc.cmag.invsuplin_integral(\n",
    "            ecc,\n",
    "            g=g,\n",
    "            h=h_param,\n",
    "            q=q,\n",
    "            tol=1e-4,\n",
    "        )\n",
    "\n",
    "        ax.plot(ecc, cumarea_fit / 100, label=\"Best Fit Model\", color='blue')\n",
    "        ax.plot(ecc, cum_area    / 100, label=\"Cumulative Surface Area\", color='gray')\n",
    "\n",
    "        ax.set_ylabel(r\"Surface Area [cm$^2$]\")\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "axs[0, 1].legend()\n",
    "axs[3, 0].set_xlabel(\"Eccentricity [deg]\")\n",
    "axs[3, 1].set_xlabel(\"Eccentricity [deg]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary plot of percent error\n",
    "\n",
    "res_mix = {'lh': [[], [], [], []], 'rh': [[], [], [], []]}\n",
    "std_ecc = np.linspace(1, 12, 100)\n",
    "\n",
    "for sid in sids_orig:\n",
    "    inv_fits = invsuplin_params[invsuplin_params['sid'] == sid]\n",
    "\n",
    "    for i, lbl in enumerate([1, 2, 3, 4]):  \n",
    "        for hemi in ['lh', 'rh']:\n",
    "\n",
    "            inv_row = inv_fits[\n",
    "                (inv_fits['label'] == lbl) &\n",
    "                (inv_fits['h'] == hemi)\n",
    "            ]\n",
    "            if len(inv_row) == 0:\n",
    "                continue\n",
    "\n",
    "            g = inv_row['g'].values[0]\n",
    "            h_param = inv_row['h_param'].values[0]   \n",
    "            q = inv_row['q'].values[0]\n",
    "\n",
    "            # empirical cumulative area\n",
    "            ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "            if ecc is None or len(ecc) == 0:\n",
    "                continue\n",
    "\n",
    "            ii = np.argsort(ecc)\n",
    "            ecc = ecc[ii]\n",
    "            srf = srf[ii]\n",
    "            cum_area = np.cumsum(srf)\n",
    "\n",
    "            # model cumulative area: inverse superlinear for all areas\n",
    "            cumarea_fit = cc.cmag.invsuplin_integral(\n",
    "                ecc,\n",
    "                g=g,\n",
    "                h=h_param,\n",
    "                q=q,\n",
    "                tol=1e-4,\n",
    "            )\n",
    "\n",
    "            # resample both onto common eccentricity grid\n",
    "            cum_area_std    = np.interp(std_ecc, ecc, cum_area)\n",
    "            cumarea_fit_std = np.interp(std_ecc, ecc, cumarea_fit)\n",
    "\n",
    "            # percent error relative to model\n",
    "            percent_err = (cumarea_fit_std - cum_area_std) / cumarea_fit_std * 100\n",
    "            percent_err[std_ecc > np.max(ecc)] = np.nan  \n",
    "\n",
    "            res_mix[hemi][lbl - 1].append(percent_err)\n",
    "\n",
    "\n",
    "diffs_mix = {h: np.array(dat) for (h, dat) in res_mix.items()}\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(7, 7), dpi=72*8,\n",
    "                        sharex=True, sharey=True)\n",
    "\n",
    "for i, lbl in enumerate([1, 2, 3, 4]):    \n",
    "    for j, hemi in enumerate(['lh', 'rh']):  \n",
    "        ax = axs[i, j]\n",
    "\n",
    "        diff_mtx = diffs_mix[hemi][lbl - 1]\n",
    "        diff_mtx = np.where(np.isfinite(diff_mtx), diff_mtx, np.nan)\n",
    "\n",
    "        med_low, med_high = cc.cmag.signed_bounds_from_abs_ranking(diff_mtx, 50)\n",
    "        p95_low, p95_high = cc.cmag.signed_bounds_from_abs_ranking(diff_mtx, 95)\n",
    "\n",
    "        ax.axhline(0, linestyle='--', color='black', linewidth=1)\n",
    "\n",
    "        ax.fill_between(std_ecc, med_low, med_high,\n",
    "                        color='0.5', alpha=0.7, label='50% of Subjects')\n",
    "        ax.fill_between(std_ecc, p95_low, p95_high,\n",
    "                        color='0.3', alpha=0.3, label='95% of Subjects')\n",
    "        ax.plot(std_ecc, np.zeros_like(std_ecc), color='blue')\n",
    "\n",
    "        ax.set_ylabel(r'Percent Error [%]')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_ylim([-30, 30])\n",
    "\n",
    "        if i == 0 and j == 1:\n",
    "            ax.legend(fontsize=10, loc='upper right')\n",
    "\n",
    "axs[3, 0].set_xlabel('Eccentricity [degree]')\n",
    "axs[3, 1].set_xlabel('Eccentricity [degree]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70102e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a178828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca33b5f3",
   "metadata": {},
   "source": [
    "# previous versions below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685d12e1",
   "metadata": {},
   "source": [
    "## hh91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a52e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict(sid=[], h=[], label=[], a=[], b=[], loss=[])\n",
    "for sid in sids_orig:\n",
    "    print(sid)\n",
    "    for h in ['lh','rh']:\n",
    "        for lbl in [1,2,3,4]:\n",
    "            try:\n",
    "                r = cc.cmag.fit_cumarea(sid, h, lbl, params0=(17.3, 0.75),method='Powell')\n",
    "            except Exception as e:\n",
    "                print(f\"  - Skipping: {type(e)}\")\n",
    "                continue\n",
    "            df['sid'].append(sid)\n",
    "            df['h'].append(h)\n",
    "            df['label'].append(lbl)\n",
    "            df['a'].append(r.x[0])\n",
    "            df['b'].append(r.x[1])\n",
    "            df['loss'].append(r.fun)\n",
    "\n",
    "HH91_params = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3da3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "HH91_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5125a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b7c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "245a0327",
   "metadata": {},
   "source": [
    "## gain params for cmag with respect to inv crowding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553eb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bouma(r, /, b=0.198, *, a=0.43, c=0.06):\n",
    "    \"\"\"Returns the visual crowding distance according to Kurzawski et al. (2025).\"\"\"\n",
    "    return b * (a + r + c*r**2)\n",
    "def inverse_Bouma_cumarea(r, /, a=0.43, b=0.198, c=0.06):\n",
    "    \"\"\"Returns the cumulative area predicted by the inverse-Bouma cortical \n",
    "    magnification model.\"\"\"\n",
    "    from numpy import pi, arctan, real_if_close\n",
    "    from numpy.lib.scimath import sqrt as csqrt\n",
    "    # The formula:\n",
    "    const = (2*pi) / b**2\n",
    "    ac4_1 = 4*a*c - 1\n",
    "    sqrt_ac4_1 = csqrt(ac4_1)\n",
    "    formula = (\n",
    "        (r + 2*c*r**2)/(ac4_1 * (a + r + c*r**2)) +\n",
    "        2*(arctan(1/sqrt_ac4_1) - arctan((2*c*r + 1)/sqrt_ac4_1)) / sqrt_ac4_1**3)\n",
    "    return const * real_if_close(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ff739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gain_inv_bouma(ecc, cum_area, b=0.198):\n",
    "    pred = inverse_Bouma_cumarea(ecc, a=0.43, b=0.198, c=0.06)\n",
    "    def mse_loss(g):\n",
    "        return np.mean((cum_area - g*pred) ** 2)\n",
    "\n",
    "    # initial guess for gain=1\n",
    "    result = minimize(mse_loss, x0=[1.0])\n",
    "    gain = result.x[0]\n",
    "\n",
    "    return gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59304e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['V1', 'V2', 'V3', 'V4']\n",
    "# plt.figure(figsize=(3.5, 3.5))\n",
    "# for i, lbl in enumerate(labels):\n",
    "#     hemi_rs = np.array(rsquareds['lh'][i] + rsquareds['rh'][i])\n",
    "#     plt.hist(hemi_rs, bins=15, alpha=0.6, label=lbl)\n",
    "#     print(np.mean(hemi_rs))\n",
    "# plt.xlabel(\"r2\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.title(\"r2 distribution by visual area (LH + RH)\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc6d89",
   "metadata": {},
   "source": [
    "### test the HH91_integral r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e60b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gain_hh91(ecc, cum_area, b=0.198):\n",
    "    pred = cc.cmag.HH91_integral(ecc, a, b)\n",
    "    def mse_loss(g):\n",
    "        return np.mean((cum_area - g * pred) ** 2)\n",
    "\n",
    "    # initial guess for gain=1\n",
    "    result = minimize(mse_loss, x0=[1.0])\n",
    "    gain = result.x[0]\n",
    "\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsquareds_hh91 = {'lh': [[],[],[],[]], 'rh': [[],[],[],[]]}\n",
    "\n",
    "for sid in sids_orig:\n",
    "    hh91_fits = HH91_params[HH91_params['sid'] == sid]\n",
    "    for i, lbl in enumerate([1, 2, 3, 4]):\n",
    "        for hemi in ['lh','rh']:\n",
    "            hfit_row = hh91_fits[(hh91_fits['label']==lbl) & (hh91_fits['h']==hemi)]\n",
    "            if len(hfit_row)==0:\n",
    "                continue\n",
    "              \n",
    "            a = hfit_row['a'].values[0]\n",
    "            b = hfit_row['b'].values[0]\n",
    "\n",
    "            ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "            ii = np.argsort(ecc)\n",
    "            ecc, srf = ecc[ii], srf[ii]\n",
    "            cum_area = np.cumsum(srf)\n",
    "            \n",
    "            cumarea_fit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "            rsquareds_hh91[hemi][i].append(model_rsquared(cumarea_fit, cum_area))\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18acf1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rsquared(pred, gold):\n",
    "    var_gold = np.var(gold)\n",
    "    error = (gold - pred)\n",
    "    mean_sse = np.mean(error**2)\n",
    "    return 1 - mean_sse / var_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b97338",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_gain = []\n",
    "rows_hh91 = []\n",
    "\n",
    "for sid in sids_orig:\n",
    "    hh91_fits = HH91_params[HH91_params['sid'] == sid]\n",
    "\n",
    "    for i, lbl in enumerate([1, 2, 3, 4]):   \n",
    "        for hemi in ['lh', 'rh']:\n",
    "\n",
    "            hfit_row = hh91_fits[\n",
    "                (hh91_fits['label'] == lbl) &\n",
    "                (hh91_fits['h'] == hemi)\n",
    "            ]\n",
    "            if len(hfit_row) == 0:\n",
    "                continue\n",
    "\n",
    "            # HH91 parameters\n",
    "            a = hfit_row['a'].values[0]\n",
    "            b = hfit_row['b'].values[0]\n",
    "\n",
    "            # empirical ecc + surface area\n",
    "            ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "            ii = np.argsort(ecc)\n",
    "            ecc = ecc[ii]\n",
    "            srf = srf[ii]\n",
    "            cum_area = np.cumsum(srf)\n",
    "\n",
    "            # ---- Bouma gain (for crowding-derived model) ----\n",
    "            gain = fit_gain_inv_bouma(ecc, cum_area)\n",
    "            rsq_bouma = model_rsquared(gain*inverse_Bouma_cumarea(ecc), cum_area)\n",
    "            rows_gain.append({\n",
    "                'sid': sid,\n",
    "                'hemi': hemi,\n",
    "                'label': lbl,\n",
    "                'gain': gain,\n",
    "                'rsq':rsq_bouma\n",
    "            })\n",
    "\n",
    "            # ---- HH91 R² (for classical model) ----\n",
    "            cumarea_fit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "            rsq_hh91 = model_rsquared(cumarea_fit, cum_area)\n",
    "\n",
    "            rows_hh91.append({\n",
    "                'sid': sid,\n",
    "                'hemi': hemi,\n",
    "                'label': lbl,\n",
    "                'rsq_hh91': rsq_hh91\n",
    "            })\n",
    "\n",
    "gain_df  = pd.DataFrame(rows_gain)\n",
    "hh91_df  = pd.DataFrame(rows_hh91)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a7280",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = ['V1', 'V2', 'V3', 'hV4']\n",
    "labels = [1, 2, 3, 4]  \n",
    "\n",
    "\n",
    "mean_r2_bouma = []\n",
    "sem_r2_bouma = []\n",
    "all_r2_bouma = []\n",
    "\n",
    "mean_r2_hh91 = []\n",
    "sem_r2_hh91 = []\n",
    "all_r2_hh91 = []\n",
    "\n",
    "for lbl in labels:\n",
    "    # Bouma R² (from gain_df)\n",
    "    r2_bouma = gain_df[gain_df['label'] == lbl]['rsq'].values\n",
    "    r2_bouma = r2_bouma[r2_bouma >= 0.25]    \n",
    "    all_r2_bouma.append(r2_bouma)\n",
    "    mean_r2_bouma.append(np.mean(r2_bouma))\n",
    "    sem_r2_bouma.append(np.std(r2_bouma) / np.sqrt(len(r2_bouma)))\n",
    "\n",
    "    # HH91 R² (from hh91_df)\n",
    "    r2_hh = hh91_df[hh91_df['label'] == lbl]['rsq_hh91'].values\n",
    "    r2_hh = r2_hh[r2_hh >= 0.25]           \n",
    "    all_r2_hh91.append(r2_hh)\n",
    "    mean_r2_hh91.append(np.mean(r2_hh))\n",
    "    sem_r2_hh91.append(np.std(r2_hh) / np.sqrt(len(r2_hh)))\n",
    "\n",
    "\n",
    "mean_r2_bouma = np.array(mean_r2_bouma)\n",
    "sem_r2_bouma = np.array(sem_r2_bouma)\n",
    "mean_r2_hh91  = np.array(mean_r2_hh91)\n",
    "sem_r2_hh91   = np.array(sem_r2_hh91)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5, 3.5), dpi=72*8)\n",
    "\n",
    "x = np.arange(len(areas))\n",
    "offset = 0.12  \n",
    "\n",
    "for i in range(len(areas)):\n",
    "    r2_b = all_r2_bouma[i]\n",
    "    ax.scatter(np.full_like(r2_b, x[i] - offset), r2_b,\n",
    "               color='gray', alpha=0.5, s=20, label='K23 (individual)' if i == 0 else None)\n",
    "\n",
    "    r2_h = all_r2_hh91[i]\n",
    "    ax.scatter(np.full_like(r2_h, x[i] + offset), r2_h,\n",
    "               color='lightblue', alpha=0.5, s=20, label='HH91 (individual)' if i == 0 else None)\n",
    "\n",
    "# Plot mean ± SEM for each model\n",
    "ax.errorbar(x - offset, mean_r2_bouma, yerr=sem_r2_bouma, fmt='o',\n",
    "            capsize=4, linewidth=1.5, markersize=6, color='black', label='K23 mean ± SEM')\n",
    "ax.errorbar(x + offset, mean_r2_hh91, yerr=sem_r2_hh91, fmt='o',\n",
    "            capsize=4, linewidth=1.5, markersize=6, color='navy', label='HH91 mean ± SEM')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(areas)\n",
    "ax.set_ylabel('R²')\n",
    "#ax.set_xlabel('Visual area')\n",
    "ax.set_title('Individual and mean R² values (K23 and HH91 models)')\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b2b054",
   "metadata": {},
   "source": [
    "## check the quality of the fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eba3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using bouma for v4 and hh91 for v1-v3\n",
    "# save for all subjects\n",
    "import os\n",
    "\n",
    "save_dir = os.path.expanduser('~/for_crowding_figures_inv_Bouma_for_V4_update')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for sid in sids_orig:\n",
    "\n",
    "    hh91_fits = HH91_params[HH91_params['sid'] == sid]\n",
    "    fig, axs = plt.subplots(4, 2, figsize=(7, 7), dpi=72*8,\n",
    "                            sharex=True, sharey=True)\n",
    "\n",
    "    for i, lbl in enumerate([1, 2, 3, 4]):   # V1, V2, V3, hV4\n",
    "        for j, hemi in enumerate(['lh', 'rh']):\n",
    "            ax = axs[i, j]\n",
    "\n",
    "            # HH91 parameter row\n",
    "            hfit_row = hh91_fits[\n",
    "                (hh91_fits['label'] == lbl) &\n",
    "                (hh91_fits['h'] == hemi)\n",
    "            ]\n",
    "            if len(hfit_row) == 0:\n",
    "                continue\n",
    "\n",
    "            a = hfit_row['a'].values[0]\n",
    "            b = hfit_row['b'].values[0]\n",
    "\n",
    "            # empirical cumulative area\n",
    "            ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "            if ecc is None or len(ecc) == 0:\n",
    "                continue\n",
    "\n",
    "            ii = np.argsort(ecc)\n",
    "            ecc = ecc[ii]\n",
    "            srf = srf[ii]\n",
    "            cum_area = np.cumsum(srf)\n",
    "\n",
    "            # Choose model: V1–V3 HH91, V4 inverse Bouma\n",
    "            if lbl in (1, 2, 3):\n",
    "                cumarea_fit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "                model_label = \"Best Fit Model\"\n",
    "            else:\n",
    "                gain_row = gain_df[\n",
    "                    (gain_df['sid'] == sid) &\n",
    "                    (gain_df['hemi'] == hemi) &\n",
    "                    (gain_df['label'] == lbl)\n",
    "                ]\n",
    "                if len(gain_row) == 0:\n",
    "                    continue\n",
    "                gain = gain_row['gain'].values[0]\n",
    "                cumarea_fit = gain * inverse_Bouma_cumarea(ecc)\n",
    "                model_label = \"Best Fit Model\"\n",
    "\n",
    "            ax.plot(ecc, cumarea_fit / 100, color='blue', label=model_label)\n",
    "            ax.plot(ecc, cum_area / 100,    color='gray', label=\"Cumulative Surface Area\")\n",
    "\n",
    "            ax.set_ylabel(r\"Surface Area [cm$^2$]\")\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "    axs[0, 1].legend()\n",
    "    axs[3, 0].set_xlabel(\"Eccentricity [deg]\")\n",
    "    axs[3, 1].set_xlabel(\"Eccentricity [deg]\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure for this subject\n",
    "    fig_path = os.path.join(save_dir, f\"fits_qc_{sid}.png\")\n",
    "    fig.savefig(fig_path, dpi=300)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single subject below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = sids_orig[1]  \n",
    "\n",
    "hh91_fits = HH91_params[HH91_params['sid'] == sid]\n",
    "fig, axs = plt.subplots(4, 2, figsize=(7, 7), dpi=72*8, sharex=True, sharey=True)\n",
    "\n",
    "for i, lbl in enumerate([1, 2, 3, 4]): \n",
    "    for j, hemi in enumerate(['lh', 'rh']):\n",
    "        ax = axs[i, j]\n",
    "\n",
    "        hfit_row = hh91_fits[\n",
    "            (hh91_fits['label'] == lbl) &\n",
    "            (hh91_fits['h'] == hemi)\n",
    "        ]\n",
    "        if len(hfit_row) == 0:\n",
    "            continue\n",
    "\n",
    "        a = hfit_row['a'].values[0]\n",
    "        b = hfit_row['b'].values[0]\n",
    "\n",
    "        ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "        ii = np.argsort(ecc)\n",
    "        ecc = ecc[ii]\n",
    "        srf = srf[ii]\n",
    "        cum_area = np.cumsum(srf)\n",
    "\n",
    "        # Decide which model to plot\n",
    "        if lbl in (1, 2, 3):   # V1–V3: HH91 model\n",
    "            cumarea_fit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "            model_label = \"Best Fit Model\"\n",
    "\n",
    "        else:  # V4: inverse-Bouma-based cumulative model using gain_df\n",
    "            gain_row = gain_df[\n",
    "                (gain_df['sid'] == sid) &\n",
    "                (gain_df['hemi'] == hemi) &\n",
    "                (gain_df['label'] == lbl)\n",
    "            ]\n",
    "            if len(gain_row) == 0:\n",
    "                continue\n",
    "\n",
    "            gain = gain_row['gain'].values[0]\n",
    "\n",
    "            cumarea_fit = gain * inverse_Bouma_cumarea(ecc)\n",
    "            model_label = \"Best Fit Model\"\n",
    "\n",
    "        # Plot model vs empirical\n",
    "        ax.plot(ecc, cumarea_fit / 100, label=model_label, color='blue')\n",
    "        ax.plot(ecc, cum_area / 100, label=\"Cumulative Surface Area\", color='gray')\n",
    "        ax.set_ylabel(r\"Surface Area [cm$^2$]\")\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "axs[0, 1].legend()\n",
    "axs[3, 0].set_xlabel(\"Eccentricity [deg]\")\n",
    "axs[3, 1].set_xlabel(\"Eccentricity [deg]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77984cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_curve(cum):\n",
    "    \"\"\"Normalize a cumulative curve to go from 0 to 100.\"\"\"\n",
    "    return 100 * (cum - cum[0]) / (cum[-1] - cum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf271847",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = sids_orig[1]\n",
    "hh91_fits = HH91_params[HH91_params['sid'] == sid]\n",
    "\n",
    "# Color + label maps\n",
    "area_labels = {1: \"V1\", 2: \"V2\", 3: \"V3\", 4: \"hV4\"}\n",
    "area_colors = {1: \"black\", 2: \"red\", 3: \"blue\", 4: \"cyan\"}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 3), dpi=72*8, sharey=True)\n",
    "\n",
    "for j, hemi in enumerate(['lh', 'rh']):\n",
    "    ax = axs[j]\n",
    "\n",
    "    for lbl in [1, 2, 3, 4]:\n",
    "\n",
    "        # -- get model parameters --\n",
    "        hfit_row = hh91_fits[\n",
    "            (hh91_fits['label'] == lbl) &\n",
    "            (hh91_fits['h'] == hemi)\n",
    "        ]\n",
    "        if len(hfit_row) == 0:\n",
    "            continue\n",
    "\n",
    "        # -- load measured cumulative area --\n",
    "        ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "        if ecc is None or len(ecc) == 0:\n",
    "            continue\n",
    "\n",
    "        ii = np.argsort(ecc)\n",
    "        ecc = ecc[ii]\n",
    "        srf = srf[ii]\n",
    "        cum_area = np.cumsum(srf)\n",
    "\n",
    "        # -- model logic --\n",
    "        if lbl in (1, 2, 3):  # HH91 for V1–V3\n",
    "            a = hfit_row['a'].values[0]\n",
    "            b = hfit_row['b'].values[0]\n",
    "            cumfit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "        else:                # inverse Bouma for V4\n",
    "            gain_row = gain_df[\n",
    "                (gain_df['sid'] == sid) &\n",
    "                (gain_df['hemi'] == hemi) &\n",
    "                (gain_df['label'] == lbl)\n",
    "            ]\n",
    "            if len(gain_row) == 0:\n",
    "                continue\n",
    "            gain = gain_row['gain'].values[0]\n",
    "            cumfit = gain * inverse_Bouma_cumarea(ecc)\n",
    "\n",
    "        # -- normalize model curve --\n",
    "        cumfit_norm = norm_curve(cumfit)\n",
    "\n",
    "        # -- plot model only, with custom color --\n",
    "        ax.plot(\n",
    "            ecc, cumfit_norm,\n",
    "            lw=2,\n",
    "            color=area_colors[lbl],\n",
    "            label=area_labels[lbl]\n",
    "        )\n",
    "\n",
    "    ax.set_title(hemi.upper())\n",
    "    ax.set_xlabel(\"Eccentricity [deg]\")\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "axs[0].set_ylabel(\"Normalized cumulative area [%]\")\n",
    "\n",
    "# Legend only on right panel\n",
    "#axs[1].legend(title=\"Area\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0fe3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def norm_curve(cum):\n",
    "    return 100 * (cum - cum[0]) / (cum[-1] - cum[0]) if cum[-1] != cum[0] else np.zeros_like(cum)\n",
    "\n",
    "\n",
    "sid = sids_orig[1]\n",
    "hh91_fits = HH91_params[HH91_params['sid'] == sid]\n",
    "\n",
    "\n",
    "area_colors = {\n",
    "    1: \"black\",\n",
    "    2: \"red\",\n",
    "    3: \"blue\",\n",
    "    4: \"cyan\",\n",
    "}\n",
    "area_labels = {\n",
    "    1: \"V1\",\n",
    "    2: \"V2\",\n",
    "    3: \"V3\",\n",
    "    4: \"hV4\",\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7, 3), dpi=72*8, sharey=True)\n",
    "\n",
    "for j, hemi in enumerate([\"lh\", \"rh\"]):\n",
    "    ax = axs[j]\n",
    "\n",
    "    for lbl in [1, 2, 3, 4]:\n",
    "\n",
    "        # get HH91 params if available\n",
    "        hfit_row = hh91_fits[\n",
    "            (hh91_fits[\"label\"] == lbl) &\n",
    "            (hh91_fits[\"h\"] == hemi)\n",
    "        ]\n",
    "        if len(hfit_row) == 0:\n",
    "            continue\n",
    "\n",
    "        # load surface area data\n",
    "        ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "        if ecc is None or len(ecc) == 0:\n",
    "            continue\n",
    "\n",
    "        # sort by eccentricity\n",
    "        ii = np.argsort(ecc)\n",
    "        ecc = ecc[ii]\n",
    "        srf = srf[ii]\n",
    "        cum_area = np.cumsum(srf)\n",
    "        cum_area_norm = norm_curve(cum_area)\n",
    "\n",
    "        # Model\n",
    "        if lbl in (1, 2, 3):   # HH91\n",
    "            a = hfit_row['a'].values[0]\n",
    "            b = hfit_row['b'].values[0]\n",
    "            cumfit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "\n",
    "        else:  # V4 inverse Bouma\n",
    "            gain_row = gain_df[\n",
    "                (gain_df[\"sid\"] == sid) &\n",
    "                (gain_df[\"hemi\"] == hemi) &\n",
    "                (gain_df[\"label\"] == lbl)\n",
    "            ]\n",
    "            if len(gain_row) == 0:\n",
    "                continue\n",
    "\n",
    "            gain = gain_row['gain'].values[0]\n",
    "            cumfit = gain * inverse_Bouma_cumarea(ecc)\n",
    "\n",
    "        cumfit_norm = norm_curve(cumfit)\n",
    "\n",
    "        # ----- Plot -----\n",
    "        color = area_colors[lbl]\n",
    "\n",
    "        # Model = solid\n",
    "        ax.plot(ecc, cumfit_norm,\n",
    "                color=color, lw=2,\n",
    "                label=area_labels[lbl] if j == 1 else None)\n",
    "\n",
    "        # Empirical = dashed\n",
    "        ax.plot(ecc, cum_area_norm,\n",
    "                color=color, lw=1.2, linestyle=\"--\")\n",
    "\n",
    "  \n",
    "    ax.set_xlabel(\"Eccentricity [deg]\")\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "axs[0].set_ylabel(\"Normalized cumulative area [%]\")\n",
    "axs[1].legend(title=\"Area\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed5171e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604495a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2523dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d3bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sid = sids_orig[1]  # choose subject\n",
    "# sid_idx = list(sids_orig).index(sid)\n",
    "\n",
    "# hh91_fits = HH91_params[HH91_params['sid'] == sid]\n",
    "# fig, axs = plt.subplots(4, 2, figsize=(7, 7), dpi=72*8, sharex=True, sharey=True)\n",
    "\n",
    "# for i, lbl in enumerate([1, 2, 3, 4]):  # V1–V4\n",
    "#     for j, hemi in enumerate(['lh', 'rh']):\n",
    "#         ax = axs[i, j]\n",
    "#         hfit_row = hh91_fits[\n",
    "#             (hh91_fits['label'] == lbl) &\n",
    "#             (hh91_fits['h'] == hemi)\n",
    "#         ]\n",
    "#         if len(hfit_row) == 0:\n",
    "#             continue\n",
    "\n",
    "#         # --- HH91 params ---\n",
    "#         a = hfit_row['a'].values[0]\n",
    "#         b = hfit_row['b'].values[0]\n",
    "\n",
    "#         # --- empirical data ---\n",
    "#         ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "#         ii = np.argsort(ecc)\n",
    "#         ecc = ecc[ii]\n",
    "#         srf = srf[ii]\n",
    "#         cum_area = np.cumsum(srf)\n",
    "\n",
    "#         # --- choose model ---\n",
    "#         if lbl in (1, 2, 3):   # V1–V3: HH91\n",
    "#             cumarea_fit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "#             panel_text = \"model: Horton & Hoyt\"\n",
    "#         else:                  # V4: Bouma inverse model\n",
    "#             gain_row = gain_df[\n",
    "#                 (gain_df['sid'] == sid) &\n",
    "#                 (gain_df['hemi'] == hemi) &\n",
    "#                 (gain_df['label'] == lbl)\n",
    "#             ]\n",
    "#             if len(gain_row) == 0:\n",
    "#                 continue\n",
    "#             gain = gain_row['gain'].values[0]\n",
    "#             cumarea_fit = gain * cmag_bouma_form(ecc)\n",
    "#             panel_text = \"model: inverse-Bouma\"\n",
    "\n",
    "#         # --- Plot ---\n",
    "#         ax.plot(ecc, cumarea_fit / 100, color='blue', label=\"Best Fit Model\")\n",
    "#         ax.plot(ecc, cum_area / 100, color='gray', label=\"Cumulative Surface Area\")\n",
    "\n",
    "#         ax.set_ylabel(r\"Surface Area [cm$^2$]\")\n",
    "#         ax.spines['top'].set_visible(False)\n",
    "#         ax.spines['right'].set_visible(False)\n",
    "\n",
    "#         # --- Add panel text (blue, 10-pt font) ---\n",
    "#         ax.text(\n",
    "#             0.05, 0.90,\n",
    "#             panel_text,\n",
    "#             transform=ax.transAxes,\n",
    "#             fontsize=10,\n",
    "#             color='blue'\n",
    "#         )\n",
    "\n",
    "# # global legend (only once)\n",
    "# handles, labels = axs[0,0].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='upper right', fontsize=10)\n",
    "\n",
    "# axs[3,0].set_xlabel(\"Eccentricity [deg]\")\n",
    "# axs[3,1].set_xlabel(\"Eccentricity [deg]\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mix = {'lh': [[], [], [], []], 'rh': [[], [], [], []]}\n",
    "std_ecc = np.linspace(1, 12, 100)\n",
    "\n",
    "for sid in sids_orig:\n",
    "    hh91_fits = HH91_params[HH91_params['sid'] == sid]\n",
    "\n",
    "    for i, lbl in enumerate([1, 2, 3, 4]):  \n",
    "        for hemi in ['lh', 'rh']:\n",
    "            hfit_row = hh91_fits[\n",
    "                (hh91_fits['label'] == lbl) &\n",
    "                (hh91_fits['h'] == hemi)\n",
    "            ]\n",
    "            if len(hfit_row) == 0:\n",
    "                continue\n",
    "\n",
    "            # HH91 params\n",
    "            a = hfit_row['a'].values[0]\n",
    "            b = hfit_row['b'].values[0]\n",
    "\n",
    "            # cum area data\n",
    "            ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "            ii = np.argsort(ecc)\n",
    "            ecc = ecc[ii]\n",
    "            srf = srf[ii]\n",
    "            cum_area = np.cumsum(srf)\n",
    "\n",
    "            if lbl in (1, 2, 3):  # V1–V3: HH91 model\n",
    "                cumarea_fit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "            else:  # V4: crowding-based \n",
    "                gain_row = gain_df[\n",
    "                    (gain_df['sid'] == sid) &\n",
    "                    (gain_df['hemi'] == hemi) &\n",
    "                    (gain_df['label'] == lbl)\n",
    "                ]\n",
    "\n",
    "                gain = gain_row['gain'].values[0]\n",
    "                cumarea_fit = gain * inverse_Bouma_cumarea(ecc)\n",
    "\n",
    "            # resample both onto common eccentricity grid\n",
    "            cum_area_std    = np.interp(std_ecc, ecc, cum_area)\n",
    "            cumarea_fit_std = np.interp(std_ecc, ecc, cumarea_fit)\n",
    "\n",
    "            # percent error relative to model\n",
    "            percent_err = (cumarea_fit_std - cum_area_std) / cumarea_fit_std * 100\n",
    "            percent_err[std_ecc > np.max(ecc)] = np.nan  \n",
    "\n",
    "            res_mix[hemi][lbl - 1].append(percent_err)\n",
    "\n",
    "diffs_mix = {h: np.array(dat) for (h, dat) in res_mix.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fca203",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2, figsize=(7, 7), dpi=72*8,\n",
    "                        sharex=True, sharey=True)\n",
    "\n",
    "for i, lbl in enumerate([1, 2, 3, 4]):    \n",
    "    for j, hemi in enumerate(['lh', 'rh']):  \n",
    "        ax = axs[i, j]\n",
    "\n",
    "        diff_mtx = diffs_mix[hemi][lbl - 1]  \n",
    "        diff_mtx = np.where(np.isfinite(diff_mtx), diff_mtx, np.nan)\n",
    "\n",
    "        med_low, med_high = cc.cmag.signed_bounds_from_abs_ranking(diff_mtx, 50)\n",
    "        p95_low, p95_high = cc.cmag.signed_bounds_from_abs_ranking(diff_mtx, 95)\n",
    "\n",
    "        ax.axhline(0, linestyle='--', color='black', linewidth=1)\n",
    "\n",
    "        ax.fill_between(std_ecc, med_low, med_high,\n",
    "                        color='0.5', alpha=0.7, label='50% of Subjects')\n",
    "        ax.fill_between(std_ecc, p95_low, p95_high,\n",
    "                        color='0.3', alpha=0.3, label='95% of Subjects')\n",
    "        ax.plot(std_ecc, np.zeros_like(std_ecc), color='blue')\n",
    "\n",
    "        ax.set_ylabel(r'Percent Error [%]')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_ylim([-30, 30])\n",
    "\n",
    "        if i == 0 and j == 1:\n",
    "            ax.legend(fontsize=10, loc='upper right')\n",
    "\n",
    "axs[3, 0].set_xlabel('Eccentricity [degree]')\n",
    "axs[3, 1].set_xlabel('Eccentricity [degree]')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac5d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ae131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c142fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c58a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85753c7a",
   "metadata": {},
   "source": [
    "## bootstrap on C.Mag fits and plot C.Mag against eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean a,b fits per label\n",
    "mean_params = HH91_params.groupby('label')[['a', 'b']].mean().reset_index()\n",
    "np.round(mean_params,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 11, 1000)\n",
    "cmag_per_label = {}\n",
    "\n",
    "# fitted Cmag for each area v1-v3\n",
    "for _, row in mean_params.iterrows():\n",
    "    label = row['label']\n",
    "    a = row['a']\n",
    "    b = row['b']\n",
    "    cmag_r = (a / (b + x))**2\n",
    "    cmag_per_label[label] = cmag_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41450967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also calculate std of a,b parameters\n",
    "np.round(HH91_params.groupby('label')[['a', 'b']].agg(['mean', 'std']).reset_index(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45360ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_v4_vals = gain_df[gain_df['label'] == 4]['gain'].values\n",
    "mean_gain_v4 = np.mean(np.sqrt(gain_v4_vals))\n",
    "# Bouma-based cmag for hV4\n",
    "cmag_v4_bouma = mean_gain_v4/ Bouma(x)\n",
    "\n",
    "cmag_per_label[4] = cmag_v4_bouma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb67a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bootstrap_samples = 10000\n",
    "bootstrap_cmag_per_label = {}\n",
    "\n",
    "for lbl in [1, 2, 3, 4]:\n",
    "\n",
    "    if lbl in [1, 2, 3]:\n",
    "        # ---- HH91 bootstrap ----\n",
    "        df_lbl = HH91_params[HH91_params['label']==lbl]\n",
    "        a_values = df_lbl['a'].values\n",
    "        b_values = df_lbl['b'].values\n",
    "        n = len(a_values)\n",
    "    \n",
    "        boot_curves = []\n",
    "        for _ in range(num_bootstrap_samples):\n",
    "            idx = np.random.choice(n, size=n, replace=True)\n",
    "            mean_a = np.mean(a_values[idx])\n",
    "            mean_b = np.mean(b_values[idx])\n",
    "            cmag_boot = (mean_a / (mean_b + x))**2\n",
    "            boot_curves.append(cmag_boot)\n",
    "\n",
    "        bootstrap_cmag_per_label[lbl] = np.array(boot_curves)\n",
    "\n",
    "    else:\n",
    "        # ---- V4: Bouma bootstrap ----\n",
    "        gain_values = gain_df[gain_df['label']==4]['gain'].values\n",
    "        n = len(gain_values)\n",
    "        \n",
    "        boot_curves = []\n",
    "        for _ in range(num_bootstrap_samples):\n",
    "            idx = np.random.choice(n, size=n, replace=True)\n",
    "            mean_gain = np.mean(np.sqrt(gain_values[idx]))\n",
    "            cmag_boot = mean_gain / Bouma(x)\n",
    "            boot_curves.append(cmag_boot)\n",
    "\n",
    "        bootstrap_cmag_per_label[lbl] = np.array(boot_curves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_v1 = bootstrap_cmag_per_label[1]\n",
    "bootstrapped_v2 = bootstrap_cmag_per_label[2]\n",
    "bootstrapped_v3 = bootstrap_cmag_per_label[3]\n",
    "bootstrapped_v4 = bootstrap_cmag_per_label[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_v1 = np.percentile(bootstrapped_v1, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v2 = np.percentile(bootstrapped_v2, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v3 = np.percentile(bootstrapped_v3, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v4 = np.percentile(bootstrapped_v4, [2.5, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 11, 1000)\n",
    "fig, ax = plt.subplots(1,1, figsize=(3.5, 3.5), dpi=72*8)\n",
    "\n",
    "# Plotting the fitted lines for each visual area\n",
    "ax.plot(x, np.sqrt(cmag_per_label[1]/2), 'black', label='V1 fitted line')\n",
    "ax.plot(x, np.sqrt(cmag_per_label[2]/2), 'red', label='V2 fitted line')\n",
    "ax.plot(x, np.sqrt(cmag_per_label[3]/2), 'magenta', label='V3 fitted line') #blue before\n",
    "ax.plot(x, cmag_per_label[4], 'cyan', label='hV4 fitted line')\n",
    "\n",
    "# Plotting the confidence intervals for each visual area\n",
    "ax.fill_between(x, \n",
    "                 np.sqrt(confidence_interval_v1[0]/2),\n",
    "                 np.sqrt(confidence_interval_v1[1]/2),\n",
    "                 color='black', alpha=0.3)\n",
    "ax.fill_between(x, \n",
    "                 np.sqrt(confidence_interval_v2[0]/2),\n",
    "                 np.sqrt(confidence_interval_v2[1]/2),\n",
    "                 color='red', alpha=0.3)\n",
    "ax.fill_between(x, \n",
    "                 np.sqrt(confidence_interval_v3[0]/2),\n",
    "                 np.sqrt(confidence_interval_v3[1]/2),\n",
    "                 color='magenta', alpha=0.3)\n",
    "ax.fill_between(x, \n",
    "                 confidence_interval_v4[0],\n",
    "                 confidence_interval_v4[1],\n",
    "                 color='cyan', alpha=0.3)\n",
    "\n",
    "# ax.set_xscale(\"log\")\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Eccentricity [deg]\")\n",
    "ax.set_ylabel(\"1D Cortical Magnification [mm/deg]\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a8057",
   "metadata": {},
   "source": [
    "## cortical crowding distance (ccd) and coefficent of variation for ccd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c5859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_ccd_1 = []\n",
    "bootstrapped_ccd_2 = []\n",
    "bootstrapped_ccd_3 = []\n",
    "bootstrapped_ccd_4 = []\n",
    "\n",
    "# Iterate through 10000 bootstrapped samples\n",
    "for i in range(10000):\n",
    "    ccd_v1 = bootstrapped[i] * np.sqrt(bootstrapped_v1[i] / 2)\n",
    "    bootstrapped_ccd_1.append(ccd_v1)\n",
    "    \n",
    "    ccd_v2 = bootstrapped[i] * np.sqrt(bootstrapped_v2[i] / 2)\n",
    "    bootstrapped_ccd_2.append(ccd_v2)\n",
    "    \n",
    "    ccd_v3 = bootstrapped[i] * np.sqrt(bootstrapped_v3[i] / 2)\n",
    "    bootstrapped_ccd_3.append(ccd_v3)\n",
    "    \n",
    "    ccd_v4 = bootstrapped[i] * bootstrapped_v4[i]\n",
    "    bootstrapped_ccd_4.append(ccd_v4)\n",
    "\n",
    "bootstrapped_ccd_1 = np.array(bootstrapped_ccd_1)\n",
    "bootstrapped_ccd_2 = np.array(bootstrapped_ccd_2)\n",
    "bootstrapped_ccd_3 = np.array(bootstrapped_ccd_3)\n",
    "bootstrapped_ccd_4 = np.array(bootstrapped_ccd_4)\n",
    "\n",
    "# Calculate the mean of bootstrapped CCD values for each visual area\n",
    "ccd1 = np.mean(bootstrapped_ccd_1, axis=0)\n",
    "ccd2 = np.mean(bootstrapped_ccd_2, axis=0)\n",
    "ccd3 = np.mean(bootstrapped_ccd_3, axis=0)\n",
    "ccd4 = np.mean(bootstrapped_ccd_4, axis=0)\n",
    "\n",
    "# Calculate the confidence interval for bootstrapped CCD values for each visual area\n",
    "confidence_interval_ccd_1 = np.percentile(bootstrapped_ccd_1,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_2 = np.percentile(bootstrapped_ccd_2,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_3 = np.percentile(bootstrapped_ccd_3,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_4 = np.percentile(bootstrapped_ccd_4,  [16, 84], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coefficient of variation for ccd_1\n",
    "mean_ccd_1 = np.mean(ccd1)\n",
    "std_ccd_1 = np.std(ccd1)\n",
    "cv_ccd_1 = std_ccd_1 / mean_ccd_1\n",
    "rounded_cv_ccd_1 = round(cv_ccd_1, 3)\n",
    "\n",
    "print(\"Coefficient of Variation (CCD 1):\", rounded_cv_ccd_1)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_2\n",
    "mean_ccd_2 = np.mean(ccd2)\n",
    "std_ccd_2 = np.std(ccd2)\n",
    "cv_ccd_2 = std_ccd_2 / mean_ccd_2\n",
    "rounded_cv_ccd_2 = round(cv_ccd_2, 3)\n",
    "print(\"Coefficient of Variation (CCD 2):\", rounded_cv_ccd_2)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_3\n",
    "mean_ccd_3 = np.mean(ccd3)\n",
    "std_ccd_3 = np.std(ccd3)\n",
    "cv_ccd_3 = std_ccd_3 / mean_ccd_3\n",
    "rounded_cv_ccd_3 = round(cv_ccd_3, 3)\n",
    "print(\"Coefficient of Variation (CCD 3):\", rounded_cv_ccd_3)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_4\n",
    "mean_ccd_4 = np.mean(ccd4)\n",
    "std_ccd_4 = np.std(ccd4)\n",
    "cv_ccd_4 = std_ccd_4 / mean_ccd_4\n",
    "rounded_cv_ccd_4 = round(cv_ccd_4, 3)\n",
    "print(\"Coefficient of Variation (CCD 4):\", rounded_cv_ccd_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coefficient of variation for ccd_1\n",
    "mean_ccd_1 = np.mean(ccd1)\n",
    "std_ccd_1 = np.std(ccd1)\n",
    "cv_ccd_1 = std_ccd_1 / mean_ccd_1\n",
    "rounded_cv_ccd_1 = round(cv_ccd_1, 3)\n",
    "\n",
    "print(\"Coefficient of Variation (CCD 1):\", rounded_cv_ccd_1)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_2\n",
    "mean_ccd_2 = np.mean(ccd2)\n",
    "std_ccd_2 = np.std(ccd2)\n",
    "cv_ccd_2 = std_ccd_2 / mean_ccd_2\n",
    "rounded_cv_ccd_2 = round(cv_ccd_2, 3)\n",
    "print(\"Coefficient of Variation (CCD 2):\", rounded_cv_ccd_2)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_3\n",
    "mean_ccd_3 = np.mean(ccd3)\n",
    "std_ccd_3 = np.std(ccd3)\n",
    "cv_ccd_3 = std_ccd_3 / mean_ccd_3\n",
    "rounded_cv_ccd_3 = round(cv_ccd_3, 3)\n",
    "print(\"Coefficient of Variation (CCD 3):\", rounded_cv_ccd_3)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_4\n",
    "mean_ccd_4 = np.mean(ccd4)\n",
    "std_ccd_4 = np.std(ccd4)\n",
    "cv_ccd_4 = std_ccd_4 / mean_ccd_4\n",
    "rounded_cv_ccd_4 = round(cv_ccd_4, 3)\n",
    "print(\"Coefficient of Variation (CCD 4):\", rounded_cv_ccd_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_cv_1 = cc.corticalcrowding.bootstrap_cv(ccd1)\n",
    "ci_1 = np.percentile(bootstrapped_cv_1, [2.5, 97.5])\n",
    "\n",
    "bootstrapped_cv_2 = cc.corticalcrowding.bootstrap_cv(ccd2)\n",
    "ci_2 = np.percentile(bootstrapped_cv_2, [2.5, 97.5])\n",
    "\n",
    "bootstrapped_cv_3 = cc.corticalcrowding.bootstrap_cv(ccd3)\n",
    "ci_3 = np.percentile(bootstrapped_cv_3, [2.5, 97.5])\n",
    "\n",
    "bootstrapped_cv_4 = cc.corticalcrowding.bootstrap_cv(ccd4)\n",
    "ci_4 = np.percentile(bootstrapped_cv_4, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65015f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ccd_1 = bootstrapped_cv_1.mean()\n",
    "cv_ccd_2 = bootstrapped_cv_2.mean()\n",
    "cv_ccd_3 = bootstrapped_cv_3.mean()\n",
    "cv_ccd_4 = bootstrapped_cv_4.mean()\n",
    "print([cv_ccd_1, cv_ccd_2, cv_ccd_3, cv_ccd_4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2af863",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_ccd_1,mean_ccd_2,mean_ccd_3,mean_ccd_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(ci_1, 3))\n",
    "print(np.round(ci_2, 3))\n",
    "print(np.round(ci_3, 3))\n",
    "print(np.round(ci_4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fc561",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ccd_values = [cv_ccd_1, cv_ccd_2, cv_ccd_3, cv_ccd_4]\n",
    "ccd_labels = ['V1', 'V2', 'V3', 'hV4']\n",
    "cv_ci_list = [(ci_1[0], ci_1[1]), (ci_2[0], ci_2[1]), (ci_3[0], ci_3[1]),(ci_4[0], ci_4[1])]\n",
    "\n",
    "lower_bound = [ci[0] for ci in cv_ci_list]\n",
    "upper_bound = [ci[1] for ci in cv_ci_list]\n",
    "\n",
    "yerr = [[cv_ccd_values[i] - lower_bound[i] for i in range(len(cv_ccd_values))],\n",
    "        [upper_bound[i] - cv_ccd_values[i] for i in range(len(cv_ccd_values))]]\n",
    "\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.bar(ccd_labels, cv_ccd_values, yerr=yerr, capsize=5, color=['gray', 'red', 'blue', 'cyan'])\n",
    "\n",
    "#plt.xlabel('Visual Areas')\n",
    "plt.ylabel('Coefficient of Variation')\n",
    "#plt.title('Coefficient of Variation for Cortical Crowding Distance')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06211fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean cortical crowding distance of each area\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.plot(x, ccd1, label='Cortical crowding distance in V1', color='black')\n",
    "plt.plot(x, ccd2, label='Cortical crowding distance in V2', color='red')\n",
    "plt.plot(x, ccd3, label='Cortical crowding distance in V3', color='blue')\n",
    "plt.plot(x, ccd4, label='Cortical crowding distance in hV4', color='cyan')\n",
    "\n",
    "plt.fill_between(x, confidence_interval_ccd_1[0], confidence_interval_ccd_1[1], color='black', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_2[0], confidence_interval_ccd_2[1], color='red', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_3[0], confidence_interval_ccd_3[1], color='blue', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_4[0], confidence_interval_ccd_4[1], color='cyan', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.xlabel('Eccentricity [deg]')\n",
    "plt.ylabel('Cortical Crowding Distance [mm]')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the cortical crowding distance\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.plot(x, ccd1/ccd1[0], color='black')\n",
    "plt.plot(x, ccd2/ccd2[0], color='red')\n",
    "plt.plot(x, ccd3/ccd3[0], color='blue')\n",
    "plt.plot(x, ccd4/ccd4[0], color='cyan')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.xlabel('Eccentricity [deg]')\n",
    "plt.ylabel('Normalized Cortical C.D. [mm]')\n",
    "#plt.xticks([2.5, 5, 10])\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927de95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b1c9864",
   "metadata": {},
   "source": [
    "## linear regression: predict crowding distance based on vmag_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768705d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average parameter values across hemispheres for each subject and label\n",
    "HH91_params_bi = HH91_params.groupby(\n",
    "    ['sid', 'label'], as_index=False\n",
    "    ).agg({\n",
    "    'a': 'mean',\n",
    "    'b': 'mean',\n",
    "    'loss': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7035ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = HH91_params_bi.merge(\n",
    "    pd.DataFrame(dict(RadialEccentricity=[2.5, 5.0, 10.0])),\n",
    "    how='cross')\n",
    "\n",
    "a = df_mean['a']\n",
    "b = df_mean['b']\n",
    "ecc = df_mean['RadialEccentricity']\n",
    "# calculate cmag based on a,b params from HH91_params_bi\n",
    "df_mean['cmag_fit'] = (a / (ecc + b))**2\n",
    "# add 1d visual magnification\n",
    "df_mean['vmag1d_fit'] = np.sqrt(1 / df_mean['cmag_fit'])\n",
    "df_mean['cmag_rad_fit'] = np.sqrt(df_mean['cmag_fit'] / 2)\n",
    "df_mean['vmag_rad_fit'] = 1.0 / df_mean['cmag_rad_fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082fff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns of crowding distance df\n",
    "mean_cd = mean_cd.rename(columns={\"ID\": \"sid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df_mean.merge(mean_cd, on=['sid', 'RadialEccentricity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a222133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean #15 subjects with both crowding distance and fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean['v4_cmag_rad'] = np.nan\n",
    "df_mean['v4_vmag'] = np.nan\n",
    "\n",
    "for sid in df_mean['sid'].unique():\n",
    "\n",
    "    # get subject's V4 gains (both hemispheres)\n",
    "    gains_v4 = gain_df[(gain_df['sid'] == sid) &\n",
    "                       (gain_df['label'] == 4)]['gain'].values\n",
    "\n",
    "    # compute mean sqrt(gain)\n",
    "    mean_gain_v4 = np.mean(np.sqrt(gains_v4))\n",
    "\n",
    "    # mask for this subject's V4 rows in df_mean\n",
    "    mask = (df_mean['sid'] == sid) & (df_mean['label'] == 4)\n",
    "\n",
    "    # get eccentricities for this subject & V4\n",
    "    ecc_vals = df_mean.loc[mask, 'RadialEccentricity'].values\n",
    "\n",
    "    # Bouma denominator (0.43 + r + 0.06 r^2)\n",
    "    bouma_vals_v4 = Bouma(ecc_vals)\n",
    "\n",
    "    # V4 cortical magnification (radial)\n",
    "    v4_cmag_vals = mean_gain_v4 / bouma_vals_v4\n",
    "\n",
    "    # assign new values\n",
    "    df_mean.loc[mask, 'v4_cmag_rad'] = v4_cmag_vals\n",
    "\n",
    "    # corresponding visual magnification = 1 / cortical_magnification\n",
    "    df_mean.loc[mask, 'v4_vmag'] = 1.0 / v4_cmag_vals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99cb4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {1: [], 2: [], 3: [], 4: []}\n",
    "slopes = {1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "for subject, subject_data in df_mean.groupby(['sid']):\n",
    "    for lbl in [1, 2, 3, 4]:\n",
    "\n",
    "        ssdf = subject_data[subject_data['label'] == lbl]\n",
    "\n",
    "        if lbl in [1, 2, 3]:  \n",
    "            # V1–V3: classical visual magnification\n",
    "            x = ssdf['vmag_rad_fit'].values  \n",
    "\n",
    "        else:  \n",
    "            # V4: Bouma-derived visual magnification\n",
    "            x = ssdf['v4_vmag'].values  \n",
    "\n",
    "        y = ssdf['CrowdingDistance'].values\n",
    "\n",
    "        # run regression (RSS + slope)\n",
    "        rss, slope = cc.regression.fit_and_evaluate(x, y)\n",
    "\n",
    "        res[lbl].append(rss)\n",
    "        slopes[lbl].append(slope)\n",
    "\n",
    "# compute summary stats\n",
    "mean_rss = [np.mean(res[l]) for l in [1, 2, 3, 4]]\n",
    "std_rss  = [np.std(res[l])  for l in [1, 2, 3, 4]]\n",
    "\n",
    "n_subjects = len(df_mean['sid'].unique())\n",
    "sem_rss = np.array(std_rss) / np.sqrt(n_subjects)\n",
    "\n",
    "print(\"Mean RSS:\", mean_rss)\n",
    "print(\"SEM RSS:\", sem_rss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['V1', 'V2', 'V3', 'hV4']\n",
    "colors = ['grey', 'red', 'magenta', 'cyan'] #blue\n",
    "\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.bar(labels, mean_rss, yerr=sem_rss, color=colors, capsize=6)\n",
    "\n",
    "plt.ylabel(\"Residual Sum of Squares [deg²]\")\n",
    "plt.title(\"Mean Residual Sum of Squares Across Visual Areas\")\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ef1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_df[gain_df['label']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d30387",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_df[gain_df['label']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean['v3_cmag_rad'] = np.nan\n",
    "df_mean['v3_vmag'] = np.nan\n",
    "\n",
    "for sid in df_mean['sid'].unique():\n",
    "\n",
    "    # get subject's V3 gains (both hemispheres)\n",
    "    gains_v3 = gain_df[(gain_df['sid'] == sid) &\n",
    "                       (gain_df['label'] == 3)]['gain'].values\n",
    "\n",
    "    # compute mean sqrt(gain)\n",
    "    mean_gain_v3 = np.mean(np.sqrt(gains_v3))\n",
    "\n",
    "    mask = (df_mean['sid'] == sid) & (df_mean['label'] == 3)\n",
    "\n",
    "    # get eccentricities for this subject & V3\n",
    "    ecc_vals = df_mean.loc[mask, 'RadialEccentricity'].values\n",
    "\n",
    "    # Bouma denominator (0.43 + r + 0.06 r^2)\n",
    "    bouma_vals_v3 = Bouma(ecc_vals)\n",
    "\n",
    "    # V3 cortical magnification (radial)\n",
    "    v3_cmag_vals = mean_gain_v3 / bouma_vals_v3\n",
    "\n",
    "    # assign new values\n",
    "    df_mean.loc[mask, 'v3_cmag_rad'] = v3_cmag_vals\n",
    "\n",
    "    # corresponding visual magnification = 1 / cortical_magnification\n",
    "    df_mean.loc[mask, 'v3_vmag'] = 1.0 / v3_cmag_vals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdbe806",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3_gain_summary = []  # list of dicts\n",
    "\n",
    "for sid in df_mean['sid'].unique():\n",
    "\n",
    "    gains_v3 = gain_df[(gain_df['sid'] == sid) &\n",
    "                       (gain_df['label'] == 3)]['gain'].values\n",
    "\n",
    "    mean_gain_v3 = np.mean(np.sqrt(gains_v3))\n",
    "\n",
    "    mask = (df_mean['sid'] == sid) & (df_mean['label'] == 3)\n",
    "    ecc_vals = df_mean.loc[mask, 'RadialEccentricity'].values\n",
    "    bouma_vals_v3 = Bouma(ecc_vals)\n",
    "    v3_cmag_vals = mean_gain_v3 / bouma_vals_v3\n",
    "\n",
    "    df_mean.loc[mask, 'v3_cmag_rad'] = v3_cmag_vals\n",
    "    df_mean.loc[mask, 'v3_vmag'] = 1.0 / v3_cmag_vals\n",
    "\n",
    "    # store info per subject\n",
    "    v3_gain_summary.append({\n",
    "        \"sid\": sid,\n",
    "        \"raw_gains\": gains_v3,\n",
    "        \"mean_sqrt_gain\": mean_gain_v3\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647619c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all raw gains from summary\n",
    "all_raw_from_summary = np.concatenate([d[\"raw_gains\"] for d in v3_gain_summary])\n",
    "all_raw_from_gain_df = gain_df[gain_df['label'] == 3]['gain'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c05d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {1: [], 2: [], 3: [], 4: []}\n",
    "slopes = {1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "for subject, subject_data in df_mean.groupby(['sid']):\n",
    "    for lbl in [1, 2, 3, 4]:\n",
    "\n",
    "        ssdf = subject_data[subject_data['label'] == lbl]\n",
    "\n",
    "\n",
    "        if lbl in [1, 2]:\n",
    "            x = ssdf['vmag_rad_fit'].values\n",
    "        elif lbl == 3:\n",
    "            x = ssdf['v3_vmag'].values\n",
    "        else:  # lbl == 4\n",
    "            x = ssdf['v4_vmag'].values\n",
    "\n",
    "        y = ssdf['CrowdingDistance'].values\n",
    "\n",
    "        # run regression (RSS + slope)\n",
    "        rss, slope = cc.regression.fit_and_evaluate(x, y)\n",
    "\n",
    "        res[lbl].append(rss)\n",
    "        slopes[lbl].append(slope)\n",
    "\n",
    "# compute summary stats\n",
    "mean_rss = [np.mean(res[l]) for l in [1, 2, 3, 4]]\n",
    "std_rss  = [np.std(res[l])  for l in [1, 2, 3, 4]]\n",
    "\n",
    "n_subjects = len(df_mean['sid'].unique())\n",
    "sem_rss = np.array(std_rss) / np.sqrt(n_subjects)\n",
    "\n",
    "print(\"Mean RSS:\", mean_rss)\n",
    "print(\"SEM RSS:\", sem_rss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['V1', 'V2', 'V3', 'V4']\n",
    "colors = ['grey', 'red', 'blue', 'cyan']\n",
    "\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.bar(labels, mean_rss, yerr=sem_rss, color=colors, capsize=6)\n",
    "\n",
    "plt.ylabel(\"Residual Sum of Squares [deg²]\")\n",
    "#plt.title(\"Mean Residual Sum of Squares Across Visual Areas\")\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b1ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00c26ff4",
   "metadata": {},
   "source": [
    "# previous code used in VSS24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cacd631",
   "metadata": {},
   "source": [
    "### bootstrap crowding distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_cd(x, b):\n",
    "    return np.log10((0.43 + x + 0.06*(x**2)) * b)\n",
    "\n",
    "# the number of bootstrap samples\n",
    "num_bootstrap_samples = 1000\n",
    "x = np.linspace(0.5,10,1000)\n",
    "eccentricities = [2.5, 5, 10]\n",
    "\n",
    "# sid_df.shape=(480,)\n",
    "sid_df = df['Observer'].values\n",
    "x_ecc = np.array(x_ecc)\n",
    "cd = np.array(cd_list)\n",
    "\n",
    "def bootstrap_fit(sids, xdata, ydata, x):\n",
    "    # unique_sids : 20 numbers\n",
    "    unique_sids = np.unique(sids)\n",
    "    bootstrapped_parameters = []\n",
    "    for _ in range(num_bootstrap_samples):\n",
    "        # each bootstrap, sample 20 subjects with replacement\n",
    "        indices = np.random.choice(unique_sids, size=len(unique_sids), replace=True)\n",
    "        indices = [np.where(sids == sid)[0] for sid in indices]\n",
    "        indices = [k for ak in indices for k in ak]\n",
    "        # 20 by 24 = 480, 480 x values and y values each\n",
    "        x_boot = xdata[indices]\n",
    "        y_boot = ydata[indices]\n",
    "        # Fit the curve to the bootstrapped sample\n",
    "        b, _ = curve_fit(func_cd, x_boot, np.log10(y_boot), p0=0.15)\n",
    "        y = (0.43 + x + 0.06*(x**2)) * b\n",
    "        bootstrapped_parameters.append(y) \n",
    "    return bootstrapped_parameters\n",
    "\n",
    "bootstrapped = bootstrap_fit(sid_df, x_ecc, cd, x)\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval_cd = np.percentile(bootstrapped, [2.5, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 10, 1000)\n",
    "# Fitted value without bootstrap\n",
    "plt.plot(x, (0.43 + x + 0.06*(x**2)) * b, 'k-', label='Fitted Crowding Distance')\n",
    "\n",
    "# Plot individual data\n",
    "plt.plot(mean_x_ecc, mean_cd_list, 'ko', alpha=0.1, label='Individual Crowding Distance')\n",
    "\n",
    "# Plot error bars\n",
    "plt.errorbar(eccentricities, mean_values, yerr=std_values, fmt='o', color='red', label='Mean ± Std')\n",
    "plt.fill_between(x, confidence_interval_cd[0], confidence_interval_cd[1], color='gray', alpha=0.3, label='95% Confidence Interval')\n",
    "\n",
    "plt.xlabel('Eccentricity (deg)')\n",
    "plt.ylabel('Crowding distance (deg)')\n",
    "plt.yscale('log')\n",
    "plt.ylim(bottom=0.1)  # Set lower limit to 0.1 (10^-1)\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12b53f",
   "metadata": {},
   "source": [
    "### bootstrap C.Mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec282a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cmag\n",
    "all_cmag_v1 = []\n",
    "all_cmag_v2 = []\n",
    "all_cmag_v3 = []\n",
    "all_cmag_v4 = []\n",
    "all_eccen_v1 = []\n",
    "all_eccen_v2 = []\n",
    "all_eccen_v3 = []\n",
    "all_eccen_v4 = []\n",
    "eccen = np.linspace(1, 11, 1000)\n",
    "subjects_added = []  \n",
    "all_mask = ('variance_explained', 0.04, 1)\n",
    "\n",
    "for sid in sids:\n",
    "    try:\n",
    "        sub = load_subject(sid)\n",
    "\n",
    "        # Calculate cmag for the subject for V1\n",
    "        v1_mask = {'and': [('visual_area', 1), all_mask]}\n",
    "        eccen_v1, cmag_v1 = ring_cmag(sub, eccen=None, mask=v1_mask)\n",
    "        all_eccen_v1.append(eccen_v1)\n",
    "        all_cmag_v1.append(cmag_v1)\n",
    "\n",
    "        # Calculate cmag for the subject for V2\n",
    "        v2_mask = {'and': [('visual_area', 2), all_mask]}\n",
    "        eccen_v2, cmag_v2 = ring_cmag(sub, eccen=None, mask=v2_mask)\n",
    "        all_eccen_v2.append(eccen_v2)\n",
    "        all_cmag_v2.append(cmag_v2)\n",
    "\n",
    "        # Calculate cmag for the subject for V3\n",
    "        v3_mask = {'and': [('visual_area', 3), all_mask]}\n",
    "        eccen_v3, cmag_v3 = ring_cmag(sub, eccen=None, mask=v3_mask)\n",
    "        all_eccen_v3.append(eccen_v3)\n",
    "        all_cmag_v3.append(cmag_v3)\n",
    "        \n",
    "        # Calculate cmag for the subject for V4\n",
    "        v4_mask = {'and': [('visual_area', 4), all_mask]}\n",
    "        eccen_v4, cmag_v4 = ring_cmag(sub, eccen=None, mask=v4_mask)\n",
    "        all_eccen_v4.append(eccen_v4)\n",
    "        all_cmag_v4.append(cmag_v4)\n",
    "        \n",
    "        subjects_added.append(sid)  # Add subject to the list of subjects added\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating cmag for subject {sid}: {e}\")\n",
    "\n",
    "\n",
    "# Convert lists to arrays\n",
    "# all_cmag_v1 = np.array(all_cmag_v1)\n",
    "# all_cmag_v2 = np.array(all_cmag_v2)\n",
    "# all_cmag_v3 = np.array(all_cmag_v3)\n",
    "# all_cmag_v4: len=35, each array has diff shape\n",
    "all_flatcmag_v4 = np.concatenate(all_cmag_v4)\n",
    "all_flateccen_v4 = np.concatenate(all_eccen_v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c90be",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccen = np.linspace(1,11, 1000)\n",
    "\n",
    "def func(x, a, b):\n",
    "    return (a / (b + x))**2\n",
    "# use all_cmag_v1 contains cmag for v1 for 29 subjects\n",
    "subjects_added = np.array(subjects_added)\n",
    "x_data = np.array(eccen)\n",
    "cmag_v1 = np.array(all_cmag_v1)\n",
    "cmag_v2 = np.array(all_cmag_v2)\n",
    "cmag_v3 = np.array(all_cmag_v3)\n",
    "cmag_v4 = np.array(all_cmag_v4)\n",
    "\n",
    "def bootstrap_fit_cmag(sids, xdata, ydata, x, p0):\n",
    "    unique_sids = np.unique(sids)\n",
    "    bootstrapped_parameters = []\n",
    "    for _ in range(num_bootstrap_samples):\n",
    "        # Sample subjects\n",
    "        indices = np.random.choice(unique_sids, size=len(unique_sids), replace=True)\n",
    "        indices = [np.where(sids == sid)[0] for sid in indices]\n",
    "        indices = [k for ak in indices for k in ak]\n",
    "        x_boot = xdata[indices]\n",
    "        y_boot = ydata[indices]\n",
    "        # Fit the curve to the bootstrapped sample\n",
    "        popt, _ = curve_fit(func, x_boot.flatten(), y_boot.flatten(),p0=p0)\n",
    "        # store the function value\n",
    "        y = (popt[0] / (popt[1] + x))**2\n",
    "        bootstrapped_parameters.append(y) \n",
    "    return bootstrapped_parameters\n",
    "\n",
    "all_eccen = np.array([x_data]*len(subjects_added))\n",
    "\n",
    "bootstrapped_v1 = bootstrap_fit_cmag(subjects_added, all_eccen, cmag_v1, eccen, p0=[17.3, 0.75])\n",
    "bootstrapped_v2 = bootstrap_fit_cmag(subjects_added, all_eccen, cmag_v2, eccen, p0=[17.3, 0.75])\n",
    "bootstrapped_v3 = bootstrap_fit_cmag(subjects_added, all_eccen, cmag_v3, eccen, p0=[17.3, 0.75])\n",
    "bootstrapped_v4 = bootstrap_fit_cmag(subjects_added, all_eccen, cmag_v4, eccen, p0=[17.3, 0.75])\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval_v1 = np.percentile(bootstrapped_v1, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v2 = np.percentile(bootstrapped_v2, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v3 = np.percentile(bootstrapped_v3, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v4 = np.percentile(bootstrapped_v4, [2.5, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb460ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting the average data for each visual area\n",
    "ax.plot(eccen, np.sqrt(average_cmag_v1/2), 'k:', label='V1')\n",
    "ax.plot(eccen, np.sqrt(average_cmag_v2/2), 'r:', label='V2')\n",
    "ax.plot(eccen, np.sqrt(average_cmag_v3/2), 'm:', label='V3')\n",
    "ax.plot(eccen, np.sqrt(average_cmag_v4/2), 'g:', label='hV4')\n",
    "\n",
    "# Plotting the fitted lines for each visual area\n",
    "ax.plot(eccen, np.sqrt((popt1[0]/(eccen+popt1[1]))**2/2), 'k', label='V1 fitted line')\n",
    "ax.plot(eccen, np.sqrt((popt2[0]/(eccen+popt2[1]))**2/2), 'r', label='V2 fitted line')\n",
    "ax.plot(eccen, np.sqrt((popt3[0]/(eccen+popt3[1]))**2/2), 'm', label='V3 fitted line')\n",
    "ax.plot(eccen, np.sqrt((popt4[0]/(eccen+popt4[1]))**2/2), 'g', label='hV4 fitted line')\n",
    "\n",
    "# Plotting the confidence intervals for each visual area\n",
    "ax.fill_between(eccen, \n",
    "                 np.sqrt(confidence_interval_v1[0]/2),\n",
    "                 np.sqrt(confidence_interval_v1[1]/2),\n",
    "                 color='k', alpha=0.3)\n",
    "ax.fill_between(eccen, \n",
    "                 np.sqrt(confidence_interval_v2[0]/2),\n",
    "                 np.sqrt(confidence_interval_v2[1]/2),\n",
    "                 color='r', alpha=0.3)\n",
    "ax.fill_between(eccen, \n",
    "                 np.sqrt(confidence_interval_v3[0]/2),\n",
    "                 np.sqrt(confidence_interval_v3[1]/2),\n",
    "                 color='m', alpha=0.3)\n",
    "ax.fill_between(eccen, \n",
    "                 np.sqrt(confidence_interval_v4[0]/2),\n",
    "                 np.sqrt(confidence_interval_v4[1]/2),\n",
    "                 color='g', alpha=0.3)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Eccentricity (deg)\")\n",
    "ax.set_ylabel(\"Radial Cortical Magnification (mm/deg)\")\n",
    "ax.set_title(\"Average Radial Cortical Magnification for V1, V2, V3, hV4\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8980017",
   "metadata": {},
   "source": [
    "### using bootstrapped fits to get cortical crowding distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dfeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to store bootstrapped CCD values for each visual area\n",
    "bootstrapped_ccd_1 = []\n",
    "bootstrapped_ccd_2 = []\n",
    "bootstrapped_ccd_3 = []\n",
    "bootstrapped_ccd_4 = []\n",
    "\n",
    "# \"bootstrapped\" here refers to crowding distance result\n",
    "for i in range(len(bootstrapped)):\n",
    "    # Calculate bootstrapped CCD for visual area 1\n",
    "    ccd_v1 = bootstrapped[i] * np.sqrt(bootstrapped_v1[i] / 2)\n",
    "    bootstrapped_ccd_1.append(ccd_v1)\n",
    "    \n",
    "    # Calculate bootstrapped CCD for visual area 2\n",
    "    ccd_v2 = bootstrapped[i] * np.sqrt(bootstrapped_v2[i] / 2)\n",
    "    bootstrapped_ccd_2.append(ccd_v2)\n",
    "    \n",
    "    # Calculate bootstrapped CCD for visual area 3\n",
    "    ccd_v3 = bootstrapped[i] * np.sqrt(bootstrapped_v3[i] / 2)\n",
    "    bootstrapped_ccd_3.append(ccd_v3)\n",
    "    \n",
    "    # Calculate bootstrapped CCD for visual area 4\n",
    "    ccd_v4 = bootstrapped[i] * np.sqrt(bootstrapped_v4[i] / 2)\n",
    "    bootstrapped_ccd_4.append(ccd_v4)\n",
    "\n",
    "# Convert lists to arrays\n",
    "bootstrapped_ccd_1 = np.array(bootstrapped_ccd_1)\n",
    "bootstrapped_ccd_2 = np.array(bootstrapped_ccd_2)\n",
    "bootstrapped_ccd_3 = np.array(bootstrapped_ccd_3)\n",
    "bootstrapped_ccd_4 = np.array(bootstrapped_ccd_4)\n",
    "\n",
    "# Calculate the mean of bootstrapped CCD values for each visual area\n",
    "xx1 = np.mean(bootstrapped_ccd_1, axis=0)\n",
    "xx2 = np.mean(bootstrapped_ccd_2, axis=0)\n",
    "xx3 = np.mean(bootstrapped_ccd_3, axis=0)\n",
    "xx4 = np.mean(bootstrapped_ccd_4, axis=0)\n",
    "\n",
    "# Calculate the confidence interval for bootstrapped CCD values for each visual area\n",
    "confidence_interval_ccd_1 = np.percentile(bootstrapped_ccd_1,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_2 = np.percentile(bootstrapped_ccd_2,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_3 = np.percentile(bootstrapped_ccd_3,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_4 = np.percentile(bootstrapped_ccd_4,  [16, 84], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74cf81",
   "metadata": {},
   "source": [
    "### coefficient of variation for cortical crowding distance at each area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ff518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coefficient of variation for ccd_1\n",
    "mean_ccd_1 = np.mean(xx1)\n",
    "std_ccd_1 = np.std(xx1)\n",
    "cv_ccd_1 = std_ccd_1 / mean_ccd_1\n",
    "rounded_cv_ccd_1 = round(cv_ccd_1, 2)\n",
    "\n",
    "print(\"Coefficient of Variation (CCD 1):\", rounded_cv_ccd_1)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_2\n",
    "mean_ccd_2 = np.mean(xx2)\n",
    "std_ccd_2 = np.std(xx2)\n",
    "cv_ccd_2 = std_ccd_2 / mean_ccd_2\n",
    "rounded_cv_ccd_2 = round(cv_ccd_2, 2)\n",
    "print(\"Coefficient of Variation (CCD 2):\", rounded_cv_ccd_2)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_3\n",
    "mean_ccd_3 = np.mean(xx3)\n",
    "std_ccd_3 = np.std(xx3)\n",
    "cv_ccd_3 = std_ccd_3 / mean_ccd_3\n",
    "rounded_cv_ccd_3 = round(cv_ccd_3, 2)\n",
    "print(\"Coefficient of Variation (CCD 3):\", rounded_cv_ccd_3)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_4\n",
    "mean_ccd_4 = np.mean(xx4)\n",
    "std_ccd_4 = np.std(xx4)\n",
    "cv_ccd_4 = std_ccd_4 / mean_ccd_4\n",
    "rounded_cv_ccd_4 = round(cv_ccd_4, 2)\n",
    "print(\"Coefficient of Variation (CCD 4):\", rounded_cv_ccd_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_cv(data, num_samples):\n",
    "    \"\"\"\n",
    "    Perform bootstrapping to compute the coefficient of variation (CV).\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy.ndarray)\n",
    "        num_samples (int): Number of bootstrap samples to generate.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array containing the bootstrapped CV values.\n",
    "    \"\"\"\n",
    "    bootstrapped_cv = []\n",
    "    n = len(data)\n",
    "    for _ in range(num_samples):\n",
    "        sample_indices = np.random.choice(range(n), size=n, replace=True)\n",
    "        bootstrapped_sample = data[sample_indices]\n",
    "        mean_sample = np.mean(bootstrapped_sample)\n",
    "        std_sample = np.std(bootstrapped_sample)\n",
    "        cv_sample = std_sample / mean_sample\n",
    "        bootstrapped_cv.append(cv_sample)\n",
    "    return np.array(bootstrapped_cv)\n",
    "\n",
    "# Perform bootstrap on CCD 1\n",
    "bootstrapped_cv_1 = bootstrap_cv(xx1, num_samples=1000)\n",
    "ci_1 = np.percentile(bootstrapped_cv_1, [2.5, 97.5])\n",
    "\n",
    "# Perform bootstrap on CCD 2\n",
    "bootstrapped_cv_2 = bootstrap_cv(xx2, num_samples=1000)\n",
    "ci_2 = np.percentile(bootstrapped_cv_2, [2.5, 97.5])\n",
    "\n",
    "# Perform bootstrap on CCD 3\n",
    "bootstrapped_cv_3 = bootstrap_cv(xx3, num_samples=1000)\n",
    "ci_3 = np.percentile(bootstrapped_cv_3, [2.5, 97.5])\n",
    "\n",
    "# Perform bootstrap on CCD 4\n",
    "bootstrapped_cv_4 = bootstrap_cv(xx4, num_samples=1000)\n",
    "ci_4 = np.percentile(bootstrapped_cv_4, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a62301",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ccd_1 = bootstrapped_cv_1.mean()\n",
    "cv_ccd_2 = bootstrapped_cv_2.mean()\n",
    "cv_ccd_3 = bootstrapped_cv_3.mean()\n",
    "cv_ccd_4 = bootstrapped_cv_4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47861a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of mean CV in each area\n",
    "cv_ccd_values = [cv_ccd_1, cv_ccd_2, cv_ccd_3, cv_ccd_4]\n",
    "ccd_labels = ['V1', 'V2', 'V3', 'V4']\n",
    "\n",
    "# a list of CI in each area\n",
    "cv_ci_list = [(ci_1[0], ci_1[1]), (ci_2[0], ci_2[1]), (ci_3[0], ci_3[1]),(ci_4[0], ci_4[1])]\n",
    "\n",
    "# lower and upper bounds of CI\n",
    "lower_bound = [ci[0] for ci in cv_ci_list]\n",
    "upper_bound = [ci[1] for ci in cv_ci_list]\n",
    "\n",
    "yerr = [[cv_ccd_values[i] - lower_bound[i] for i in range(len(cv_ccd_values))],\n",
    "        [upper_bound[i] - cv_ccd_values[i] for i in range(len(cv_ccd_values))]]\n",
    "\n",
    "# bar plot with error bars\n",
    "plt.bar(ccd_labels, cv_ccd_values, yerr=yerr, capsize=5, color=['grey', 'red', 'magenta', 'green'])\n",
    "\n",
    "plt.xlabel('Visual Areas')\n",
    "plt.ylabel('Coefficient of Variation')\n",
    "plt.title('Coefficient of Variation for Cortical Crowding Distance')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cortical crowding distance vs eccen\n",
    "x = np.linspace(0.5, 10, 1000)\n",
    "plt.plot(x, xx1, label='Cortical crowding distance in V1', color='black')\n",
    "plt.plot(x, xx2, label='Cortical crowding distance in V2', color='red')\n",
    "plt.plot(x, xx3, label='Cortical crowding distance in V3', color='magenta')\n",
    "plt.plot(x, xx4, label='Cortical crowding distance in hV4', color='green')\n",
    "\n",
    "# Confidence intervals\n",
    "plt.fill_between(x, confidence_interval_ccd_1[0], confidence_interval_ccd_1[1], color='black', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_2[0], confidence_interval_ccd_2[1], color='red', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_3[0], confidence_interval_ccd_3[1], color='magenta', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_4[0], confidence_interval_ccd_4[1], color='green', alpha=0.3)\n",
    "\n",
    "plt.xlabel('Eccentricity (deg)')\n",
    "plt.ylabel('Cortical Crowding Distance (mm)')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5b8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8f8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "neuro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
