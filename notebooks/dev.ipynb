{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f7af612-e71d-4dfc-a477-088a7f79c1b6",
   "metadata": {},
   "source": [
    "# Development Notebook for Cortical Crowding Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f43079",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8a076-56ce-45b0-950d-b70220b4d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neuropythy as ny\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.optimize\n",
    "from scipy.stats import gmean\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ad992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpl.rcParams['font.family'] = 'Arial'\n",
    "mpl.rcParams['font.family'] = 'HelveticaNeue'\n",
    "mpl.rcParams['font.size'] = 10\n",
    "mpl.rcParams['font.weight'] = 'light'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "mpl.rcParams['figure.dpi'] = 576  # 72*8\n",
    "mpl.rcParams['hatch.color'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328aa4ac-48d3-46ba-8748-e8c287d3edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to be able to load in libraries that are in this repository's src directory,\n",
    "# so we add src to the system path:\n",
    "try:\n",
    "    import corticalcrodwing as cc\n",
    "except ModuleNotFoundError:\n",
    "    # This probably happens because the corticalcrowding library hasn't been\n",
    "    # installed yet; we can add the src directory to the path to work around\n",
    "    # this here.\n",
    "    sys.path.append('../src')\n",
    "    # Now we can import corticalcrowding from the src directory:\n",
    "    import corticalcrowding as cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a085564f",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The root path where data is stored:\n",
    "data_path = Path('/data/crowding')\n",
    "\n",
    "# The crowding data CSV file:\n",
    "crowding_data_filename = data_path / 'crowding_data_withID.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb702d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of subjects:\n",
    "sids_NYU = [\n",
    "    'sub-wlsubj070',\n",
    "    'sub-wlsubj114',\n",
    "    'sub-wlsubj121',\n",
    "    'sub-wlsubj135']\n",
    "\n",
    "# 36 is used\n",
    "sids_NEI = [ \n",
    "    'sub-wlsubj119',\n",
    "    'sub-wlsubj127',\n",
    "    'sub-wlsubj136',\n",
    "    'sub-wlsubj137',\n",
    "    'sub-wlsubj143',\n",
    "    'sub-wlsubj144',\n",
    "    'sub-wlsubj145',\n",
    "    'sub-wlsubj146',\n",
    "    'sub-wlsubj147',\n",
    "    'sub-wlsubj148',\n",
    "    'sub-wlsubj149',\n",
    "    'sub-wlsubj150',\n",
    "    'sub-wlsubj151',\n",
    "    'sub-wlsubj152',\n",
    "    'sub-wlsubj153',\n",
    "    'sub-wlsubj154',\n",
    "    'sub-wlsubj155',\n",
    "    'sub-wlsubj156',\n",
    "    'sub-wlsubj157',\n",
    "    'sub-wlsubj158',\n",
    "    'sub-wlsubj159',\n",
    "    'sub-wlsubj160',\n",
    "    'sub-wlsubj161',\n",
    "    'sub-wlsubj162',\n",
    "    'sub-wlsubj163',\n",
    "    'sub-wlsubj164',\n",
    "    'sub-wlsubj165',\n",
    "    'sub-wlsubj166',\n",
    "    'sub-wlsubj167',\n",
    "    'sub-wlsubj168',\n",
    "    'sub-wlsubj170',\n",
    "    'sub-wlsubj171',\n",
    "    'sub-wlsubj172',\n",
    "    'sub-wlsubj173',\n",
    "    'sub-wlsubj174',\n",
    "    'sub-wlsubj175',\n",
    "    'sub-wlsubj176']\n",
    "\n",
    "sids_orig = sids_NYU + sids_NEI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac4774",
   "metadata": {},
   "source": [
    "## Noah's explorations of the crowding data (2025-10-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77dfcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crowding_data = pd.read_csv(crowding_data_filename)\n",
    "\n",
    "crowddat = crowding_data.rename(\n",
    "    columns=dict(\n",
    "        Eccen_X='x', Eccen_Y='y',\n",
    "        CrowdingDistance='crowding_distance',\n",
    "        RadialEccentricity='eccentricity',\n",
    "        FlankinDirection='flankers',\n",
    "        ID='sid',\n",
    "        Session='session'))\n",
    "crowddat['hemi'] = np.where(crowddat['x'] < 0, 'rh', 'lh')\n",
    "crowddat.loc[crowddat['x'].values == 0, 'hemi'] = 'lr'\n",
    "theta = np.arctan2(crowddat['y'], crowddat['x'])\n",
    "meridian_no = np.round(np.mod(theta * 180/np.pi + 360, 360) / 360 * 4).astype(int)\n",
    "meridians = np.array(['right', 'upper', 'left', 'lower'])\n",
    "crowddat['meridian'] = meridians[meridian_no]\n",
    "crowddat = crowddat[\n",
    "    ['sid', 'hemi', 'meridian', 'eccentricity', 'flankers', 'session',\n",
    "     'x', 'y',\n",
    "     'crowding_distance']]\n",
    "crowddat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict(sid=[], hemi=[], label=[], a=[], b=[], loss=[])\n",
    "for sid in sids_orig:\n",
    "    print(sid)\n",
    "    for h in ['lh','rh','lr']:\n",
    "        for lbl in [1,2,3,4]:\n",
    "            try:\n",
    "                r = cc.cmag.fit_cumarea(sid, h, lbl)\n",
    "            except Exception as e:\n",
    "                print(f\"  - Skipping: {type(e)}\")\n",
    "                continue\n",
    "            df['sid'].append(sid)\n",
    "            df['hemi'].append(h)\n",
    "            df['label'].append(lbl)\n",
    "            df['a'].append(r.x[0])\n",
    "            df['b'].append(r.x[1])\n",
    "            df['loss'].append(r.fun)\n",
    "cmagdat = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.merge(crowddat, cmagdat, on=('sid', 'hemi'))\n",
    "\n",
    "cmag_areal = cc.cmag.HH91(\n",
    "    dataframe['eccentricity'],\n",
    "    dataframe['a'],\n",
    "    dataframe['b'])\n",
    "cmag_rad = np.sqrt(cmag_areal / 2)\n",
    "cmag_tan = cmag_rad * 2\n",
    "vmag_rad = 1 / cmag_rad\n",
    "vmag_tan = 1 / cmag_tan\n",
    "\n",
    "d_pred = np.empty_like(cmag_rad)\n",
    "flankers = dataframe['flankers'].values\n",
    "cmag_pred = np.where(flankers == 'radial', cmag_rad, cmag_tan)\n",
    "vmag_pred = np.where(flankers == 'radial', vmag_rad, vmag_tan)\n",
    "\n",
    "dataframe['cmag_are'] = cmag_areal\n",
    "dataframe['cmag_rad'] = cmag_rad\n",
    "dataframe['cmag_tan'] = cmag_tan\n",
    "dataframe['vmag_rad'] = vmag_rad\n",
    "dataframe['vmag_tan'] = vmag_tan\n",
    "dataframe['cmag_lin'] = cmag_pred\n",
    "dataframe['vmag_lin'] = vmag_pred\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d0643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crowddist_model(df, params):\n",
    "    (d_hrz, d_upp, d_low) = (params[0], params[0], params[0])\n",
    "    gains_sid = params[1:]\n",
    "    (ii_upp, ii_low) = [\n",
    "        df['meridian'] == k for k in ('upper', 'lower')]\n",
    "    ii_hrz = ~(ii_upp | ii_low)\n",
    "    (ii_hrz, ii_upp, ii_low) = [\n",
    "        np.where(ii)[0] for ii in (ii_hrz, ii_upp, ii_low)]\n",
    "    (ii_hrz, ii_upp, ii_low) = [\n",
    "        ii[np.argsort(df['sid'].values[ii])]\n",
    "        for ii in (ii_hrz, ii_upp, ii_low)]\n",
    "    (vm_hrz, vm_upp, vm_low) = [\n",
    "        df['vmag_lin'].values[ii]\n",
    "        for ii in (ii_hrz, ii_upp, ii_low)]\n",
    "    dpred_hrz = vm_hrz * d_hrz\n",
    "    dpred_upp = vm_upp * d_upp\n",
    "    dpred_low = vm_low * d_low\n",
    "    if len(gains_sid) > 0:\n",
    "        sii = np.empty(len(df), dtype=int)\n",
    "        dfsids = df['sid'].values\n",
    "        for (k,sid) in enumerate(np.unique(dfsids)):\n",
    "            sii[dfsids == sid] = k\n",
    "        dpred_hrz *= gains_sid[sii[ii_hrz]]\n",
    "        dpred_upp *= gains_sid[sii[ii_upp]]\n",
    "        dpred_low *= gains_sid[sii[ii_low]]\n",
    "    dpred = np.empty_like(df['cmag_lin'].values)\n",
    "    dpred[ii_hrz] = dpred_hrz\n",
    "    dpred[ii_upp] = dpred_upp\n",
    "    dpred[ii_low] = dpred_low\n",
    "    return dpred\n",
    "def crowddist_loss(data, label, params, tx=True):\n",
    "    if tx:\n",
    "        params = np.exp(params)\n",
    "    df = data[data['label'] == label]\n",
    "    dpred = crowddist_model(df, params)\n",
    "    d = df['crowding_distance']\n",
    "    diff = d - dpred\n",
    "    return np.var(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, /, scale=1):\n",
    "    \"\"\"Returns the sigmoid function of the argument.\n",
    "    \n",
    "    The sigmoid function is defined as: ``sigmoid(x) = 1 / (1 + exp(-x))``.\n",
    "    It is the inverse of the ``logit`` function; i.e., if ``p = sigmoid(x)``\n",
    "    then ``x = logit(p)``.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : number-like\n",
    "        The argument (or arguments) to the sigmoid function.\n",
    "    scale : float, optional\n",
    "        The scale of the sigmoid (default: 1). ``sigmoid(x, s)`` is equivalent\n",
    "        to ``sigmoid(x * s, 1)``.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    number-like\n",
    "        The sigmoid of `x`.\n",
    "    \"\"\"\n",
    "    return 1/(1 + np.exp(-scale*x))\n",
    "def logit(p, /, scale=1):\n",
    "    \"\"\"Returns the logit function of the argument.\n",
    "    \n",
    "    The logit function is defined as: ``logit(p) = log(p / (1 - p))``.\n",
    "    It is the inverse of the ``sigmoid`` function; i.e., if ``p = sigmoid(x)``\n",
    "    then ``x = logit(p)``.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p : number-like\n",
    "        The argument (or arguments) to the logit function.\n",
    "    scale : float, optional\n",
    "        The scale of the logit (default: 1). ``logit(p, s)`` is equivalent\n",
    "        to ``logit(p / s, 1)``.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    number-like\n",
    "        The logit of `p`.\n",
    "    \"\"\"\n",
    "    return np.log(p / (1 - p)) / scale\n",
    "class CrowdingModel:\n",
    "    \"\"\"A model of visual crowding that assumes a fixed crowding distance on the\n",
    "    cortical surface.\n",
    "    \"\"\"\n",
    "    __slots__ = (\n",
    "        's',\n",
    "        'g_upp',\n",
    "        'g_low',\n",
    "        'is_optform')\n",
    "    def __init__(self, s=1.4, g_upp=9/16, g_low=15/16, optform=False):\n",
    "        # Check the arguments:\n",
    "        if isinstance(s, CrowdingModel):\n",
    "            # Make a copy and ignore the other arguments.\n",
    "            self.s = s.s\n",
    "            self.g_upp = s.g_upp\n",
    "            self.g_low = s.g_low\n",
    "            self.is_optform = s.is_optform\n",
    "            return\n",
    "        s = float(s)\n",
    "        if not optform and s <= 0:\n",
    "            raise ValueError(\"s must me a float greater than 0\")\n",
    "        g_upp = float(g_upp)\n",
    "        if not optform and (g_upp <= 1/3 or g_upp >= 5/3):\n",
    "            raise ValueError(\"g_upp must be a float between 0.5 and 1.5\")\n",
    "        g_low = float(g_low)\n",
    "        if not optform and (g_low <= 1/3 or g_low >= 5/3):\n",
    "            raise ValueError(\"g_low must be a float between 0.5 and 1.5\")\n",
    "        # Set the member values:\n",
    "        self.s = s\n",
    "        self.g_upp = g_upp\n",
    "        self.g_low = g_low\n",
    "        # The normal init function doesn't create transformed arguments.\n",
    "        self.is_optform = optform\n",
    "    @staticmethod\n",
    "    def _toform(is_inform, val, txfn):\n",
    "        return val if is_inform else txfn(val)\n",
    "    @staticmethod\n",
    "    def _g_tx(g):\n",
    "        return logit((3 * g - 1)/4)\n",
    "    @staticmethod\n",
    "    def _g_xt(g):\n",
    "        return (4 * sigmoid(g) + 1) / 3\n",
    "    @property\n",
    "    def s_stdform(self):\n",
    "        return CrowdingModel._toform(not self.is_optform, self.s, np.exp)\n",
    "    @property\n",
    "    def s_optform(self):\n",
    "        return CrowdingModel._toform(self.is_optform, self.s, np.log)\n",
    "    @property\n",
    "    def g_upp_stdform(self):\n",
    "        return CrowdingModel._toform(\n",
    "            not self.is_optform, self.g_upp, CrowdingModel._g_xt)\n",
    "    @property\n",
    "    def g_upp_optform(self):\n",
    "        return CrowdingModel._toform(\n",
    "            self.is_optform, self.g_upp, CrowdingModel._g_tx)\n",
    "    @property\n",
    "    def g_low_stdform(self):\n",
    "        return CrowdingModel._toform(\n",
    "            not self.is_optform, self.g_low, CrowdingModel._g_xt)\n",
    "    @property\n",
    "    def g_low_optform(self):\n",
    "        return CrowdingModel._toform(\n",
    "            self.is_optform, self.g_low, CrowdingModel._g_tx)\n",
    "    @property\n",
    "    def params_stdform(self):\n",
    "        if not self.is_optform:\n",
    "            return (self.s, self.g_upp, self.g_low)\n",
    "        return (self.s_stdform, self.g_upp_stdform, self.g_low_stdform)\n",
    "    @property\n",
    "    def params_optform(self):\n",
    "        if self.is_optform:\n",
    "            return (self.s, self.g_upp, self.g_low)\n",
    "        return (self.s_optform, self.g_upp_optform, self.g_low_optform)\n",
    "    @property\n",
    "    def params(self):\n",
    "        return self.params_optform if self.is_optform else self.params_stdform\n",
    "    @property\n",
    "    def g_hrz_stdform(self):\n",
    "        (_, gu, gl) = self.params_stdform\n",
    "        return 2 - (gu + gl)/2\n",
    "    @property\n",
    "    def g_hrz_optform(self):\n",
    "        return logit(self.g_hrz_stdform - 0.5)\n",
    "    @property\n",
    "    def g_hrz(self):\n",
    "        return self.g_hrz_optform if self.is_optform else self.g_hrz_stdform\n",
    "    @property\n",
    "    def hva(self):\n",
    "        g_hrz = self.g_hrz_stdform\n",
    "        g_upp = self.g_upp_stdform\n",
    "        g_low = self.g_low_stdform\n",
    "        g_vrt = (g_upp + g_low) / 2\n",
    "        return 2 * (g_hrz - g_vrt) / (g_hrz + g_vrt)\n",
    "    @property\n",
    "    def vma(self):\n",
    "        g_upp = self.g_upp_stdform\n",
    "        g_low = self.g_low_stdform\n",
    "        return 2 * (g_low - g_upp) / (g_low + g_upp)\n",
    "    def to_optform(self):\n",
    "        if self.is_optform:\n",
    "            return type(self)(self)\n",
    "        s_optform = np.log(self.s)\n",
    "        g_upp_optform = logit(self.g_upp - 0.5)\n",
    "        g_low_optform = logit(self.g_low - 0.5)\n",
    "        return type(self)(s_optform, g_upp_optform, g_low_optform, True)\n",
    "    def to_stdform(self):\n",
    "        if not self.is_optform:\n",
    "            return type(self)(self)\n",
    "        s = np.exp(self.s)\n",
    "        g_upp = 0.5 + sigmoid(self.g_upp)\n",
    "        g_low = 0.5 + sigmoid(self.g_low)\n",
    "        return type(self)(s, g_upp, g_low)\n",
    "    def predict(self, *,\n",
    "                dataframe=dataframe,\n",
    "                vdst_meas_key='crowding_distance',\n",
    "                cmag_meas_key='cmag_lin',\n",
    "                meridian_key='meridian',\n",
    "                cdst_tag='cdst',\n",
    "                cmag_tag='cmag',\n",
    "                vdst_tag='vdst',\n",
    "                vmag_tag='vmag',\n",
    "                hma_tag='hma',\n",
    "                vma_tag='vma',\n",
    "                meas_tag='meas',\n",
    "                pred_tag='pred',\n",
    "                **kwargs):\n",
    "        # Make a copy of the dataframe.\n",
    "        dataframe = pd.DataFrame(dataframe)\n",
    "        for (k,v) in kwargs.items():\n",
    "            dataframe = dataframe[dataframe[k] == v]\n",
    "        # We need our parameters and derived parameters:\n",
    "        (s_pred, g_upper, g_lower) = self.params_stdform\n",
    "        g_horiz = self.g_hrz_stdform\n",
    "        g_vert = (g_upper + g_lower) / 2\n",
    "        # Get the measurements from the dataframe:\n",
    "        vdst_meas = dataframe[vdst_meas_key]  # in deg\n",
    "        cmag_meas = dataframe[cmag_meas_key]  # in mm/deg\n",
    "        # The model actually predicts a slightly different cmag, based on the\n",
    "        # part of the visual field represented.\n",
    "        ii_upper = dataframe[meridian_key] == 'upper'\n",
    "        ii_lower = dataframe[meridian_key] == 'lower'\n",
    "        ii_horiz = ~(ii_upper | ii_lower)\n",
    "        cmag_meas = np.array(cmag_meas)\n",
    "        cmag_meas[ii_upper] *= g_upper\n",
    "        cmag_meas[ii_lower] *= g_lower\n",
    "        cmag_meas[ii_horiz] *= g_horiz\n",
    "        cmag_pred = s_pred / vdst_meas\n",
    "        # The model predicts the same cortical distance everywhere.\n",
    "        dataframe[f'{cdst_tag}_{meas_tag}'] = cmag_meas * vdst_meas\n",
    "        dataframe[f'{cdst_tag}_{pred_tag}'] = s_pred\n",
    "        dataframe[f'{cmag_tag}_{meas_tag}'] = cmag_meas\n",
    "        dataframe[f'{cmag_tag}_{pred_tag}'] = cmag_pred\n",
    "        dataframe[f'{vdst_tag}_{meas_tag}'] = vdst_meas\n",
    "        dataframe[f'{vdst_tag}_{pred_tag}'] = s_pred / cmag_meas\n",
    "        dataframe[f'{vmag_tag}_{meas_tag}'] = 1/cmag_meas\n",
    "        dataframe[f'{vmag_tag}_{pred_tag}'] = 1/cmag_pred\n",
    "        dataframe[f'{hma_tag}_{pred_tag}'] = (g_horiz - g_vert) / g_horiz\n",
    "        dataframe[f'{vma_tag}_{pred_tag}'] = (g_lower - g_upper) / g_upper\n",
    "        return dataframe\n",
    "    def loss(self, /, prop='cdst', *, dataframe=dataframe, **kwargs):\n",
    "        if isinstance(prop, str):\n",
    "            prop = (prop,)\n",
    "        df = self.predict(dataframe=dataframe, **kwargs)\n",
    "        meastag = kwargs.get('meas_tag', 'meas')\n",
    "        predtag = kwargs.get('pred_tag', 'pred')\n",
    "        l = 0\n",
    "        for p in prop: \n",
    "            meas = df[f\"{p}_{meastag}\"]\n",
    "            pred = df[f\"{p}_{predtag}\"]\n",
    "            p_loss = np.mean((meas - pred)**2)\n",
    "            l += p_loss\n",
    "        return l\n",
    "    def loss_opt(self, params, /,\n",
    "                 prop='cdst', *,\n",
    "                 dataframe=dataframe, **kwargs):\n",
    "        # Params are assumed to be in optform.\n",
    "        if not self.is_optform:\n",
    "            self.is_optform = True\n",
    "        (self.s, self.g_upp, self.g_low) = params\n",
    "        return self.loss(prop=prop, dataframe=dataframe, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from functools import partial\n",
    "\n",
    "prop = ('cmag')\n",
    "fits = []\n",
    "mdls = []\n",
    "for lbl in (1,2,3,4):\n",
    "    model = CrowdingModel()\n",
    "    df = dataframe[dataframe['label'] == lbl]\n",
    "    params = np.array(model.params_optform)\n",
    "    fit = minimize(\n",
    "        partial(model.loss_opt, prop=prop, label=lbl, dataframe=df),\n",
    "        params)\n",
    "    fit.x[:] = model.params_stdform\n",
    "    fits.append(fit)\n",
    "    mdls.append(model)\n",
    "params = np.stack([fit.x for fit in fits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ccd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[float(mdls[k-1].loss(prop=prop, label=k))\n",
    " for k in (1,2,3,4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751db979",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddeb5f6",
   "metadata": {},
   "source": [
    "The basic model we're using:\n",
    "\n",
    "```text\n",
    "s: cortical crowding [mm]\n",
    "v: visual crowding [deg]\n",
    "m: cortical mag [mm/deg]\n",
    "\n",
    "s / v = m\n",
    "\n",
    "S (predicted s)\n",
    "V (predicted v)\n",
    "M (predicted m)\n",
    "\n",
    "min (S - mv)  ==> hV4 is best!\n",
    "min (V - s/m) ==> V2 is best!\n",
    "min (M - s/v) ==> hV4\n",
    "\n",
    "min (M - s/v)**2\n",
    "min (1/M - v/s)**2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04993156",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig,axs) = plt.subplots(2,2, figsize=(7,7), dpi=72*8, sharex=True, sharey=True)\n",
    "\n",
    "colors = np.array(['c','r','k'])\n",
    "markers = np.array(['o','s','^'])\n",
    "\n",
    "for (lbl,ax) in zip([1,2,3,4], axs.flat):\n",
    "    df = mdls[lbl-1].predict(label=lbl, dataframe=dataframe)\n",
    "    x = df['vdst_meas']\n",
    "    y = df['cdst_meas']\n",
    "    print(np.mean((x-y)**2))\n",
    "    hem = df['hemi']\n",
    "    ecc = df['eccentricity']\n",
    "    mer = df['meridian']\n",
    "    mrk = markers[\n",
    "        #(mer == 'upper') + (mer == 'lower')*2]\n",
    "        (ecc == 5) + 2*(ecc == 10)]\n",
    "    clr = colors[\n",
    "        #(hem == 'rh') + (hem == 'lr')*2]\n",
    "        #(ecc == 5) + 2*(ecc == 10)]\n",
    "        (mer == 'upper') + (mer == 'lower')*2]\n",
    "    clr = np.abs(x - y)\n",
    "    for m in markers:\n",
    "        ii = (mrk == m)\n",
    "        ax.scatter(x[ii], y[ii], c=clr[ii], marker=m, s=4, alpha=0.5)\n",
    "    ax.set_title(f'V{lbl}')\n",
    "    if lbl > 2:\n",
    "        ax.set_xlabel('Meas. Crowding Dist. [deg]')\n",
    "    if lbl == 1 or lbl == 3:\n",
    "        ax.set_ylabel('Pred. Crowding Dist. [deg]')\n",
    "    ax.plot([0,8],[0,8], ':', c='0.5', zorder=-1, lw=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355c2085",
   "metadata": {},
   "source": [
    "## Crowding Distance Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9cbdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each subject has 1 crowding distance value at each eccentricity\n",
    "mean_cd = (\n",
    "    crowding_data\n",
    "    .groupby(['ID','RadialEccentricity'])\n",
    "    ['CrowdingDistance']\n",
    "    .apply(gmean)\n",
    "    .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_list = crowding_data['CrowdingDistance'].tolist()\n",
    "mean_cd_list = mean_cd['CrowdingDistance'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 dfs based on the eccentricities in the dataframe:\n",
    "crowding_eccens = np.unique(crowding_data['RadialEccentricity'])\n",
    "assert len(crowding_eccens) == 3\n",
    "(ecc_1, ecc_2, ecc_3) = crowding_eccens\n",
    "\n",
    "mean_1 = mean_cd[mean_cd['RadialEccentricity'] == ecc_1]\n",
    "n_1 = len(mean_1)\n",
    "m_1 = mean_1['CrowdingDistance'].mean()\n",
    "st_1 = mean_1['CrowdingDistance'].std()\n",
    "\n",
    "mean_2 = mean_cd[mean_cd['RadialEccentricity'] == ecc_2]\n",
    "n_2 = len(mean_2)\n",
    "m_2 = mean_2['CrowdingDistance'].mean()\n",
    "st_2 = mean_2['CrowdingDistance'].std()\n",
    "\n",
    "mean_3 = mean_cd[mean_cd['RadialEccentricity'] == ecc_3]\n",
    "n_3 = len(mean_3)\n",
    "m_3 = mean_3['CrowdingDistance'].mean()\n",
    "st_3 = mean_3['CrowdingDistance'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ecc = crowding_data['RadialEccentricity'].tolist()\n",
    "mean_x_ecc = mean_cd['RadialEccentricity'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The crowding distance function in terms of eccentricity function described\n",
    "# by Kurzawski et al. (2023):\n",
    "Kurzawski2023_cd = cc.crowding.Kurzawski2023_cd\n",
    "\n",
    "# Fit the b parameter using this function by minimizing log error.\n",
    "b, _ = curve_fit(cc.crowding.log_Kurzawski2023_cd, x_ecc, np.log10(cd_list), p0=0.15)\n",
    "b = b[0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21810d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values = [m_1, m_2, m_3]\n",
    "std_values = [st_1, st_2, st_3]\n",
    "sem_values = np.array([st_1, st_2, st_3]) / np.sqrt([n_1, n_2, n_3])\n",
    "eccentricities = [ecc_1, ecc_2, ecc_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559446f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the bouma factor\n",
    "[val / div for val, div in zip(mean_values, eccentricities)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd336fc2",
   "metadata": {},
   "source": [
    "### bootstrap on crowding distance fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bootstrap_samples = 1000\n",
    "x = np.linspace(0.5,11,1000)\n",
    "eccentricities = [2.5, 5, 10]\n",
    "\n",
    "sid_df = crowding_data['ID'].values\n",
    "x_ecc = np.array(x_ecc)\n",
    "cd = np.array(cd_list)\n",
    "\n",
    "bootstrapped = cc.crowding.bootstrap_fit(sid_df, x_ecc, cd, x, num_bootstrap_samples)\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval_cd = np.percentile(bootstrapped, [2.5, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4264cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.5, 3))\n",
    "\n",
    "# Fitted value without bootstrap\n",
    "plt.plot(x, (0.43 + x + 0.06*(x**2)) * b, 'k-', label='Fitted Crowding Distance')\n",
    "\n",
    "# Plot individual data\n",
    "plt.plot(mean_x_ecc, mean_cd_list, 'ko', alpha=0.1, label='Individual Crowding Distance')\n",
    "\n",
    "# Plot error bars\n",
    "plt.errorbar(eccentricities, mean_values, yerr=std_values, fmt='o', color='red', label='Mean ± Std')\n",
    "plt.fill_between(x, confidence_interval_cd[0], confidence_interval_cd[1], color='gray', alpha=0.3, label='95% Confidence Interval')\n",
    "\n",
    "plt.xlabel('Eccentricity (deg)')\n",
    "plt.ylabel('Crowding distance (deg)')\n",
    "\n",
    "plt.ylim(bottom=0.1)  # Set lower limit to 0.1 (10^-1)\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd0c570",
   "metadata": {},
   "source": [
    "## Fit Cortical Magnification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a52e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dict(sid=[], h=[], label=[], a=[], b=[], loss=[])\n",
    "for sid in sids_orig:\n",
    "    print(sid)\n",
    "    for h in ['lh','rh']:\n",
    "        for lbl in [1,2,3,4]:\n",
    "            try:\n",
    "                r = cc.cmag.fit_cumarea(sid, h, lbl)\n",
    "            except Exception as e:\n",
    "                print(f\"  - Skipping: {type(e)}\")\n",
    "                continue\n",
    "            df['sid'].append(sid)\n",
    "            df['h'].append(h)\n",
    "            df['label'].append(lbl)\n",
    "            df['a'].append(r.x[0])\n",
    "            df['b'].append(r.x[1])\n",
    "            df['loss'].append(r.fun)\n",
    "HH91_params = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b2b054",
   "metadata": {},
   "source": [
    "## check the quality of the fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'lh': [[],[],[],[]], 'rh': [[],[],[],[]]}\n",
    "std_ecc = np.linspace(0.25, 12, 100)\n",
    "for sid in sids_orig:\n",
    "\n",
    "    hh91_fits = HH91_params[HH91_params['sid'] == sid]\n",
    "\n",
    "    for i, lbl in enumerate([1, 2, 3, 4]):\n",
    "        for j, hemi in enumerate(['lh','rh']):\n",
    "            hfit_row = hh91_fits[(hh91_fits['label'] == lbl) & (hh91_fits['h'] == hemi)]\n",
    "            if len(hfit_row) == 0:\n",
    "                continue\n",
    "\n",
    "            a = hfit_row['a'].values[0]\n",
    "            b = hfit_row['b'].values[0]\n",
    "\n",
    "            (ecc,srf) = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "            ii = np.argsort(ecc)\n",
    "            ecc = ecc[ii]\n",
    "            cum_area = np.cumsum(srf[ii])\n",
    "\n",
    "            cumarea_fit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "            \n",
    "            cum_area = np.interp(std_ecc, ecc, cum_area)\n",
    "            cumarea_fit = np.interp(std_ecc, ecc, cumarea_fit)\n",
    "            \n",
    "            diff = cumarea_fit - cum_area\n",
    "            diff[std_ecc > np.max(ecc)] = np.nan\n",
    "            res[hemi][lbl - 1].append(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = {\n",
    "    h: np.array(dat)\n",
    "    for (h,dat) in res.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261da959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean a,b fits per hemisphere and label\n",
    "avg_ab = HH91_params.groupby(['label', 'h'])[['a', 'b']].mean()\n",
    "avg_ab = avg_ab.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a53b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(fig, axs) = plt.subplots(4, 2, figsize=(7, 7), dpi=288, sharex=True, sharey=True)\n",
    "\n",
    "for i, lbl in enumerate([1, 2, 3, 4]):\n",
    "    for j, hemi in enumerate(['lh', 'rh']):\n",
    "        ax = axs[i, j]\n",
    "\n",
    "        hfit_row = avg_ab[(avg_ab['label'] == lbl) & (avg_ab['h'] == hemi)]\n",
    "        a = hfit_row['a'].values[0]\n",
    "        b = hfit_row['b'].values[0]\n",
    "\n",
    "        (ecc, srf) = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "        ii = np.argsort(ecc)\n",
    "        ecc = ecc[ii]\n",
    "        cum_area = np.cumsum(srf[ii])\n",
    "\n",
    "        cumarea_fit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "        cumarea_fit = np.interp(std_ecc, ecc, cumarea_fit)\n",
    "\n",
    "        diff_mtx = diffs[hemi][lbl - 1]\n",
    "        diff_mtx = np.where(np.isfinite(diff_mtx), diff_mtx, np.nan)\n",
    "\n",
    "        # abs-percentile bounds\n",
    "        med_low, med_high = cc.cmag.signed_bounds_from_abs_ranking(diff_mtx, 50)\n",
    "        p95_low, p95_high = cc.cmag.signed_bounds_from_abs_ranking(diff_mtx, 95)\n",
    "\n",
    "        # scale to cumulative-area units\n",
    "        y_med_low  = (cumarea_fit + med_low) / 100\n",
    "        y_med_high = (cumarea_fit + med_high) / 100\n",
    "        y_p95_low  = (cumarea_fit + p95_low) / 100\n",
    "        y_p95_high = (cumarea_fit + p95_high) / 100\n",
    "\n",
    "        ax.plot(std_ecc, cumarea_fit/100, color='blue', label=\"H&H Model Fit\")\n",
    "\n",
    "        # dark gray: 50% \n",
    "        ax.fill_between(std_ecc, y_med_low, y_med_high, color='0.5', alpha=0.7, label='50% of Data')\n",
    "\n",
    "        # light gray: 95% \n",
    "        ax.fill_between(std_ecc, y_p95_low, y_p95_high, color='0.3', alpha=0.3, label='95% of Data')\n",
    "        \n",
    "        axs[3,0].set_xlabel('Eccentricity [degree]')\n",
    "        axs[3,1].set_xlabel('Eccentricity [degree]')\n",
    "        ax.set_ylabel(r'Surface Area [cm$^2$]')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        if i == 0 and j == 1:\n",
    "            ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a figure for each subject\n",
    "\n",
    "save_dir = os.path.expanduser('~/for_crowding_figures')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for sid in sids_orig:\n",
    "    hh91_fits = HH91_params[HH91_params['sid'] == sid]\n",
    "    fig, axs = plt.subplots(4, 2, figsize=(7, 7), dpi=72*8, sharex=True, sharey=True)\n",
    "\n",
    "    for i, lbl in enumerate([1, 2, 3, 4]):\n",
    "        for j, hemi in enumerate(['lh', 'rh']):\n",
    "            ax = axs[i, j]\n",
    "            hfit_row = hh91_fits[(hh91_fits['label'] == lbl) & (hh91_fits['h'] == hemi)]\n",
    "            if len(hfit_row) == 0:\n",
    "                continue\n",
    "\n",
    "            a = hfit_row['a'].values[0]\n",
    "            b = hfit_row['b'].values[0]\n",
    "            ecc, srf = cc.cmag.cmag_basics(sid, hemi, lbl)\n",
    "            ii = np.argsort(ecc)\n",
    "            ecc = ecc[ii]\n",
    "            cum_area = np.cumsum(srf[ii])\n",
    "            cumarea_fit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "\n",
    "            ax.plot(ecc, cumarea_fit / 100, label=\"H&H Model Fit\", color='blue') \n",
    "            ax.plot(ecc, cum_area / 100, label=\"Cumulative Surface Area\", color='gray')\n",
    "            ax.set_ylabel(r'Surface Area [cm$^2$]')\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "    axs[0, 1].legend()\n",
    "    axs[3, 0].set_xlabel('Eccentricity [degree]')\n",
    "    axs[3, 1].set_xlabel('Eccentricity [degree]')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    fig_path = os.path.join(save_dir, f'fits_qc_{sid}.png')\n",
    "    fig.savefig(fig_path)\n",
    "    plt.close(fig)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85753c7a",
   "metadata": {},
   "source": [
    "## bootstrap on C.Mag fits and plot C.Mag against eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean a,b fits per label\n",
    "mean_params = HH91_params.groupby('label')[['a', 'b']].mean().reset_index()\n",
    "np.round(mean_params,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 11, 1000)\n",
    "cmag_per_label = {}\n",
    "\n",
    "# fitted Cmag for each area\n",
    "for _, row in mean_params.iterrows():\n",
    "    label = row['label']\n",
    "    a = row['a']\n",
    "    b = row['b']\n",
    "    cmag_r = (a / (b + x))**2\n",
    "    cmag_per_label[label] = cmag_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41450967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also calculate std of a,b parameters\n",
    "np.round(HH91_params.groupby('label')[['a', 'b']].agg(['mean', 'std']).reset_index(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bootstrap_samples = 1000\n",
    "\n",
    "bootstrap_cmag_per_label = {}\n",
    "\n",
    "for lbl in [1,2,3,4]:\n",
    "    df_lbl = HH91_params[HH91_params['label']==lbl]\n",
    "    a_values = df_lbl['a'].values\n",
    "    b_values = df_lbl['b'].values\n",
    "\n",
    "    # Subjects added to keep track\n",
    "    sids = df_lbl['sid'].values\n",
    "\n",
    "    boot_curves = []\n",
    "    n = len(a_values)\n",
    "\n",
    "    for _ in range(num_bootstrap_samples):\n",
    "        indices = np.random.choice(n, size=n, replace=True)\n",
    "        mean_a = np.mean(a_values[indices])\n",
    "        mean_b = np.mean(b_values[indices])\n",
    "\n",
    "        # cmag curve\n",
    "        cmag_boot = (mean_a / (mean_b + x))**2\n",
    "        boot_curves.append(cmag_boot)\n",
    "\n",
    "    # shape (1000, 1000)\n",
    "    boot_curves = np.array(boot_curves)\n",
    "    bootstrap_cmag_per_label[lbl] = boot_curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_v1 = bootstrap_cmag_per_label[1]\n",
    "bootstrapped_v2 = bootstrap_cmag_per_label[2]\n",
    "bootstrapped_v3 = bootstrap_cmag_per_label[3]\n",
    "bootstrapped_v4 = bootstrap_cmag_per_label[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_v1 = np.percentile(bootstrapped_v1, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v2 = np.percentile(bootstrapped_v2, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v3 = np.percentile(bootstrapped_v3, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v4 = np.percentile(bootstrapped_v4, [2.5, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(3.5, 3.5), dpi=72*8)\n",
    "\n",
    "# Plotting the fitted lines for each visual area\n",
    "ax.plot(x, np.sqrt(cmag_per_label[1]/2), 'k', label='V1 fitted line')\n",
    "ax.plot(x, np.sqrt(cmag_per_label[2]/2), 'r', label='V2 fitted line')\n",
    "ax.plot(x, np.sqrt(cmag_per_label[3]/2), 'm', label='V3 fitted line')\n",
    "ax.plot(x, np.sqrt(cmag_per_label[4]/2), 'cyan', label='hV4 fitted line')\n",
    "\n",
    "# Plotting the confidence intervals for each visual area\n",
    "ax.fill_between(x, \n",
    "                 np.sqrt(confidence_interval_v1[0]/2),\n",
    "                 np.sqrt(confidence_interval_v1[1]/2),\n",
    "                 color='k', alpha=0.3)\n",
    "ax.fill_between(x, \n",
    "                 np.sqrt(confidence_interval_v2[0]/2),\n",
    "                 np.sqrt(confidence_interval_v2[1]/2),\n",
    "                 color='r', alpha=0.3)\n",
    "ax.fill_between(x, \n",
    "                 np.sqrt(confidence_interval_v3[0]/2),\n",
    "                 np.sqrt(confidence_interval_v3[1]/2),\n",
    "                 color='m', alpha=0.3)\n",
    "ax.fill_between(x, \n",
    "                 np.sqrt(confidence_interval_v4[0]/2),\n",
    "                 np.sqrt(confidence_interval_v4[1]/2),\n",
    "                 color='cyan', alpha=0.3)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Eccentricity [deg]\")\n",
    "ax.set_ylabel(\"Radial Cortical Magnification [mm/deg]\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a8057",
   "metadata": {},
   "source": [
    "## cortical crowding distance (ccd) and coefficent of variation for ccd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c5859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_ccd_1 = []\n",
    "bootstrapped_ccd_2 = []\n",
    "bootstrapped_ccd_3 = []\n",
    "bootstrapped_ccd_4 = []\n",
    "\n",
    "# Iterate through 1000 bootstrapped samples\n",
    "for i in range(1000):\n",
    "    ccd_v1 = bootstrapped[i] * np.sqrt(bootstrapped_v1[i] / 2)\n",
    "    bootstrapped_ccd_1.append(ccd_v1)\n",
    "    \n",
    "    ccd_v2 = bootstrapped[i] * np.sqrt(bootstrapped_v2[i] / 2)\n",
    "    bootstrapped_ccd_2.append(ccd_v2)\n",
    "    \n",
    "    ccd_v3 = bootstrapped[i] * np.sqrt(bootstrapped_v3[i] / 2)\n",
    "    bootstrapped_ccd_3.append(ccd_v3)\n",
    "    \n",
    "    ccd_v4 = bootstrapped[i] * np.sqrt(bootstrapped_v4[i] / 2)\n",
    "    bootstrapped_ccd_4.append(ccd_v4)\n",
    "\n",
    "bootstrapped_ccd_1 = np.array(bootstrapped_ccd_1)\n",
    "bootstrapped_ccd_2 = np.array(bootstrapped_ccd_2)\n",
    "bootstrapped_ccd_3 = np.array(bootstrapped_ccd_3)\n",
    "bootstrapped_ccd_4 = np.array(bootstrapped_ccd_4)\n",
    "\n",
    "# Calculate the mean of bootstrapped CCD values for each visual area\n",
    "ccd1 = np.mean(bootstrapped_ccd_1, axis=0)\n",
    "ccd2 = np.mean(bootstrapped_ccd_2, axis=0)\n",
    "ccd3 = np.mean(bootstrapped_ccd_3, axis=0)\n",
    "ccd4 = np.mean(bootstrapped_ccd_4, axis=0)\n",
    "\n",
    "# Calculate the confidence interval for bootstrapped CCD values for each visual area\n",
    "confidence_interval_ccd_1 = np.percentile(bootstrapped_ccd_1,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_2 = np.percentile(bootstrapped_ccd_2,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_3 = np.percentile(bootstrapped_ccd_3,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_4 = np.percentile(bootstrapped_ccd_4,  [16, 84], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coefficient of variation for ccd_1\n",
    "mean_ccd_1 = np.mean(ccd1)\n",
    "std_ccd_1 = np.std(ccd1)\n",
    "cv_ccd_1 = std_ccd_1 / mean_ccd_1\n",
    "rounded_cv_ccd_1 = round(cv_ccd_1, 3)\n",
    "\n",
    "print(\"Coefficient of Variation (CCD 1):\", rounded_cv_ccd_1)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_2\n",
    "mean_ccd_2 = np.mean(ccd2)\n",
    "std_ccd_2 = np.std(ccd2)\n",
    "cv_ccd_2 = std_ccd_2 / mean_ccd_2\n",
    "rounded_cv_ccd_2 = round(cv_ccd_2, 3)\n",
    "print(\"Coefficient of Variation (CCD 2):\", rounded_cv_ccd_2)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_3\n",
    "mean_ccd_3 = np.mean(ccd3)\n",
    "std_ccd_3 = np.std(ccd3)\n",
    "cv_ccd_3 = std_ccd_3 / mean_ccd_3\n",
    "rounded_cv_ccd_3 = round(cv_ccd_3, 3)\n",
    "print(\"Coefficient of Variation (CCD 3):\", rounded_cv_ccd_3)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_4\n",
    "mean_ccd_4 = np.mean(ccd4)\n",
    "std_ccd_4 = np.std(ccd4)\n",
    "cv_ccd_4 = std_ccd_4 / mean_ccd_4\n",
    "rounded_cv_ccd_4 = round(cv_ccd_4, 3)\n",
    "print(\"Coefficient of Variation (CCD 4):\", rounded_cv_ccd_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_cv_1 = cc.corticalcrowding.bootstrap_cv(ccd1)\n",
    "ci_1 = np.percentile(bootstrapped_cv_1, [2.5, 97.5])\n",
    "\n",
    "bootstrapped_cv_2 = cc.corticalcrowding.bootstrap_cv(ccd2)\n",
    "ci_2 = np.percentile(bootstrapped_cv_2, [2.5, 97.5])\n",
    "\n",
    "bootstrapped_cv_3 = cc.corticalcrowding.bootstrap_cv(ccd3)\n",
    "ci_3 = np.percentile(bootstrapped_cv_3, [2.5, 97.5])\n",
    "\n",
    "bootstrapped_cv_4 = cc.corticalcrowding.bootstrap_cv(ccd4)\n",
    "ci_4 = np.percentile(bootstrapped_cv_4, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65015f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ccd_1 = bootstrapped_cv_1.mean()\n",
    "cv_ccd_2 = bootstrapped_cv_2.mean()\n",
    "cv_ccd_3 = bootstrapped_cv_3.mean()\n",
    "cv_ccd_4 = bootstrapped_cv_4.mean()\n",
    "print([cv_ccd_1, cv_ccd_2, cv_ccd_3, cv_ccd_4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(ci_1, 2))\n",
    "print(np.round(ci_2, 2))\n",
    "print(np.round(ci_3, 2))\n",
    "print(np.round(ci_4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d278dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ccd_values = [cv_ccd_1, cv_ccd_2, cv_ccd_3, cv_ccd_4]\n",
    "ccd_labels = ['V1', 'V2', 'V3', 'V4']\n",
    "cv_ci_list = [(ci_1[0], ci_1[1]), (ci_2[0], ci_2[1]), (ci_3[0], ci_3[1]),(ci_4[0], ci_4[1])]\n",
    "\n",
    "lower_bound = [ci[0] for ci in cv_ci_list]\n",
    "upper_bound = [ci[1] for ci in cv_ci_list]\n",
    "\n",
    "yerr = [[cv_ccd_values[i] - lower_bound[i] for i in range(len(cv_ccd_values))],\n",
    "        [upper_bound[i] - cv_ccd_values[i] for i in range(len(cv_ccd_values))]]\n",
    "\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.bar(ccd_labels, cv_ccd_values, yerr=yerr, capsize=5, color=['grey', 'red', 'magenta', 'cyan'])\n",
    "\n",
    "plt.xlabel('Visual Areas')\n",
    "plt.ylabel('Coefficient of Variation')\n",
    "plt.title('Coefficient of Variation for Cortical Crowding Distance')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e21bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean cortical crowding distance of each area\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.plot(x, ccd1, label='Cortical crowding distance in V1', color='black')\n",
    "plt.plot(x, ccd2, label='Cortical crowding distance in V2', color='red')\n",
    "plt.plot(x, ccd3, label='Cortical crowding distance in V3', color='magenta')\n",
    "plt.plot(x, ccd4, label='Cortical crowding distance in hV4', color='cyan')\n",
    "\n",
    "plt.fill_between(x, confidence_interval_ccd_1[0], confidence_interval_ccd_1[1], color='black', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_2[0], confidence_interval_ccd_2[1], color='red', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_3[0], confidence_interval_ccd_3[1], color='magenta', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_4[0], confidence_interval_ccd_4[1], color='cyan', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.xlabel('Eccentricity (deg)')\n",
    "plt.ylabel('Cortical Crowding Distance (mm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the cortical crowding distance\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.plot(x, ccd1/ccd1[0], color='black')\n",
    "plt.plot(x, ccd2/ccd2[0], color='red')\n",
    "plt.plot(x, ccd3/ccd3[0], color='magenta')\n",
    "plt.plot(x, ccd4/ccd4[0], color='cyan')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.xlabel('Eccentricity (deg)')\n",
    "plt.ylabel('Normalized Cortical C.D. (mm)')\n",
    "#plt.xticks([2.5, 5, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927de95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37c59fbd",
   "metadata": {},
   "source": [
    "## linear regression: predict crowding distance based on vmag_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768705d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average parameter values across hemispheres for each subject and label\n",
    "HH91_params_bi = HH91_params.groupby(\n",
    "    ['sid', 'label'], as_index=False\n",
    "    ).agg({\n",
    "    'a': 'mean',\n",
    "    'b': 'mean',\n",
    "    'loss': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7035ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = HH91_params_bi.merge(\n",
    "    pd.DataFrame(dict(RadialEccentricity=[2.5, 5.0, 10.0])),\n",
    "    how='cross')\n",
    "\n",
    "a = df_mean['a']\n",
    "b = df_mean['b']\n",
    "ecc = df_mean['RadialEccentricity']\n",
    "# calculate cmag based on a,b params from HH91_params_bi\n",
    "df_mean['cmag_fit'] = (a / (ecc + b))**2\n",
    "# add 1d visual magnification\n",
    "df_mean['vmag1d_fit'] = np.sqrt(1 / df_mean['cmag_fit'])\n",
    "df_mean['cmag_rad_fit'] = np.sqrt(df_mean['cmag_fit'] / 2)\n",
    "df_mean['vmag_rad_fit'] = 1.0 / df_mean['cmag_rad_fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082fff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns of crowding distance df\n",
    "mean_cd = mean_cd.rename(columns={\"ID\": \"sid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df_mean.merge(mean_cd, on=['sid', 'RadialEccentricity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a222133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean #15 subjects with both crowding distance and fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e882270",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig,axs) = plt.subplots(2, 2, figsize=(7,7), dpi=72*8, sharex=True, sharey=True)\n",
    "\n",
    "cm = mpl.cm.jet\n",
    "\n",
    "for (lbl,ax) in zip([1,2,3,4], axs.flat):\n",
    "    ax.set_title(f'V{lbl}')\n",
    "    df = df_mean[df_mean['label'] == lbl]\n",
    "    sids = np.unique(df['sid'].values)\n",
    "    for (ii,sid) in enumerate(sids):\n",
    "        df_sid = df[df['sid'] == sid]\n",
    "        x = df_sid['vmag_rad_fit']\n",
    "        y = df_sid['CrowdingDistance']\n",
    "        ax.plot(x, y, '.-', c=cm(ii / (len(sids) - 1)), alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf0750",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "for subject, subject_data in df_mean.groupby(['sid']):\n",
    "    if (subject_data['b'] > 5).any():\n",
    "        continue\n",
    "    for lbl in [1, 2, 3, 4]:\n",
    "        ssdf = subject_data[subject_data['label'] == lbl]\n",
    "        #x = ssdf['vmag1d_fit'].values\n",
    "        x = ssdf['vmag_rad_fit'].values\n",
    "        y = ssdf['CrowdingDistance'].values\n",
    "        rss, coef = cc.regression.fit_and_evaluate(x, y)\n",
    "        res[lbl].append(rss)\n",
    "\n",
    "mean_rss = [np.mean(res[l]) for l in [1, 2, 3, 4]]\n",
    "std_rss  = [np.std(res[l])  for l in [1, 2, 3, 4]]\n",
    "n_subjects = 15\n",
    "sem_rss  = np.array(std_rss) / np.sqrt(n_subjects)\n",
    "\n",
    "print(mean_rss)\n",
    "print(std_rss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b9f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['V1', 'V2', 'V3', 'V4']\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(labels, mean_rss, yerr=sem_rss)\n",
    "plt.ylabel(\"RSS (Residual Sum of Squares)\")\n",
    "plt.title(\"Mean RSS with Standard Error Across Visual Areas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12431455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00c26ff4",
   "metadata": {},
   "source": [
    "# previous code used in VSS24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cacd631",
   "metadata": {},
   "source": [
    "### bootstrap crowding distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_cd(x, b):\n",
    "    return np.log10((0.43 + x + 0.06*(x**2)) * b)\n",
    "\n",
    "# the number of bootstrap samples\n",
    "num_bootstrap_samples = 1000\n",
    "x = np.linspace(0.5,10,1000)\n",
    "eccentricities = [2.5, 5, 10]\n",
    "\n",
    "# sid_df.shape=(480,)\n",
    "sid_df = df['Observer'].values\n",
    "x_ecc = np.array(x_ecc)\n",
    "cd = np.array(cd_list)\n",
    "\n",
    "def bootstrap_fit(sids, xdata, ydata, x):\n",
    "    # unique_sids : 20 numbers\n",
    "    unique_sids = np.unique(sids)\n",
    "    bootstrapped_parameters = []\n",
    "    for _ in range(num_bootstrap_samples):\n",
    "        # each bootstrap, sample 20 subjects with replacement\n",
    "        indices = np.random.choice(unique_sids, size=len(unique_sids), replace=True)\n",
    "        indices = [np.where(sids == sid)[0] for sid in indices]\n",
    "        indices = [k for ak in indices for k in ak]\n",
    "        # 20 by 24 = 480, 480 x values and y values each\n",
    "        x_boot = xdata[indices]\n",
    "        y_boot = ydata[indices]\n",
    "        # Fit the curve to the bootstrapped sample\n",
    "        b, _ = curve_fit(func_cd, x_boot, np.log10(y_boot), p0=0.15)\n",
    "        y = (0.43 + x + 0.06*(x**2)) * b\n",
    "        bootstrapped_parameters.append(y) \n",
    "    return bootstrapped_parameters\n",
    "\n",
    "bootstrapped = bootstrap_fit(sid_df, x_ecc, cd, x)\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval_cd = np.percentile(bootstrapped, [2.5, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.5, 10, 1000)\n",
    "# Fitted value without bootstrap\n",
    "plt.plot(x, (0.43 + x + 0.06*(x**2)) * b, 'k-', label='Fitted Crowding Distance')\n",
    "\n",
    "# Plot individual data\n",
    "plt.plot(mean_x_ecc, mean_cd_list, 'ko', alpha=0.1, label='Individual Crowding Distance')\n",
    "\n",
    "# Plot error bars\n",
    "plt.errorbar(eccentricities, mean_values, yerr=std_values, fmt='o', color='red', label='Mean ± Std')\n",
    "plt.fill_between(x, confidence_interval_cd[0], confidence_interval_cd[1], color='gray', alpha=0.3, label='95% Confidence Interval')\n",
    "\n",
    "plt.xlabel('Eccentricity (deg)')\n",
    "plt.ylabel('Crowding distance (deg)')\n",
    "plt.yscale('log')\n",
    "plt.ylim(bottom=0.1)  # Set lower limit to 0.1 (10^-1)\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12b53f",
   "metadata": {},
   "source": [
    "### bootstrap C.Mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec282a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cmag\n",
    "all_cmag_v1 = []\n",
    "all_cmag_v2 = []\n",
    "all_cmag_v3 = []\n",
    "all_cmag_v4 = []\n",
    "all_eccen_v1 = []\n",
    "all_eccen_v2 = []\n",
    "all_eccen_v3 = []\n",
    "all_eccen_v4 = []\n",
    "eccen = np.linspace(1, 11, 1000)\n",
    "subjects_added = []  \n",
    "all_mask = ('variance_explained', 0.04, 1)\n",
    "\n",
    "for sid in sids:\n",
    "    try:\n",
    "        sub = load_subject(sid)\n",
    "\n",
    "        # Calculate cmag for the subject for V1\n",
    "        v1_mask = {'and': [('visual_area', 1), all_mask]}\n",
    "        eccen_v1, cmag_v1 = ring_cmag(sub, eccen=None, mask=v1_mask)\n",
    "        all_eccen_v1.append(eccen_v1)\n",
    "        all_cmag_v1.append(cmag_v1)\n",
    "\n",
    "        # Calculate cmag for the subject for V2\n",
    "        v2_mask = {'and': [('visual_area', 2), all_mask]}\n",
    "        eccen_v2, cmag_v2 = ring_cmag(sub, eccen=None, mask=v2_mask)\n",
    "        all_eccen_v2.append(eccen_v2)\n",
    "        all_cmag_v2.append(cmag_v2)\n",
    "\n",
    "        # Calculate cmag for the subject for V3\n",
    "        v3_mask = {'and': [('visual_area', 3), all_mask]}\n",
    "        eccen_v3, cmag_v3 = ring_cmag(sub, eccen=None, mask=v3_mask)\n",
    "        all_eccen_v3.append(eccen_v3)\n",
    "        all_cmag_v3.append(cmag_v3)\n",
    "        \n",
    "        # Calculate cmag for the subject for V4\n",
    "        v4_mask = {'and': [('visual_area', 4), all_mask]}\n",
    "        eccen_v4, cmag_v4 = ring_cmag(sub, eccen=None, mask=v4_mask)\n",
    "        all_eccen_v4.append(eccen_v4)\n",
    "        all_cmag_v4.append(cmag_v4)\n",
    "        \n",
    "        subjects_added.append(sid)  # Add subject to the list of subjects added\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating cmag for subject {sid}: {e}\")\n",
    "\n",
    "\n",
    "# Convert lists to arrays\n",
    "# all_cmag_v1 = np.array(all_cmag_v1)\n",
    "# all_cmag_v2 = np.array(all_cmag_v2)\n",
    "# all_cmag_v3 = np.array(all_cmag_v3)\n",
    "# all_cmag_v4: len=35, each array has diff shape\n",
    "all_flatcmag_v4 = np.concatenate(all_cmag_v4)\n",
    "all_flateccen_v4 = np.concatenate(all_eccen_v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c90be",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccen = np.linspace(1,11, 1000)\n",
    "\n",
    "def func(x, a, b):\n",
    "    return (a / (b + x))**2\n",
    "# use all_cmag_v1 contains cmag for v1 for 29 subjects\n",
    "subjects_added = np.array(subjects_added)\n",
    "x_data = np.array(eccen)\n",
    "cmag_v1 = np.array(all_cmag_v1)\n",
    "cmag_v2 = np.array(all_cmag_v2)\n",
    "cmag_v3 = np.array(all_cmag_v3)\n",
    "cmag_v4 = np.array(all_cmag_v4)\n",
    "\n",
    "def bootstrap_fit_cmag(sids, xdata, ydata, x, p0):\n",
    "    unique_sids = np.unique(sids)\n",
    "    bootstrapped_parameters = []\n",
    "    for _ in range(num_bootstrap_samples):\n",
    "        # Sample subjects\n",
    "        indices = np.random.choice(unique_sids, size=len(unique_sids), replace=True)\n",
    "        indices = [np.where(sids == sid)[0] for sid in indices]\n",
    "        indices = [k for ak in indices for k in ak]\n",
    "        x_boot = xdata[indices]\n",
    "        y_boot = ydata[indices]\n",
    "        # Fit the curve to the bootstrapped sample\n",
    "        popt, _ = curve_fit(func, x_boot.flatten(), y_boot.flatten(),p0=p0)\n",
    "        # store the function value\n",
    "        y = (popt[0] / (popt[1] + x))**2\n",
    "        bootstrapped_parameters.append(y) \n",
    "    return bootstrapped_parameters\n",
    "\n",
    "all_eccen = np.array([x_data]*len(subjects_added))\n",
    "\n",
    "bootstrapped_v1 = bootstrap_fit_cmag(subjects_added, all_eccen, cmag_v1, eccen, p0=[17.3, 0.75])\n",
    "bootstrapped_v2 = bootstrap_fit_cmag(subjects_added, all_eccen, cmag_v2, eccen, p0=[17.3, 0.75])\n",
    "bootstrapped_v3 = bootstrap_fit_cmag(subjects_added, all_eccen, cmag_v3, eccen, p0=[17.3, 0.75])\n",
    "bootstrapped_v4 = bootstrap_fit_cmag(subjects_added, all_eccen, cmag_v4, eccen, p0=[17.3, 0.75])\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval_v1 = np.percentile(bootstrapped_v1, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v2 = np.percentile(bootstrapped_v2, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v3 = np.percentile(bootstrapped_v3, [2.5, 97.5], axis=0)\n",
    "confidence_interval_v4 = np.percentile(bootstrapped_v4, [2.5, 97.5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb460ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting the average data for each visual area\n",
    "ax.plot(eccen, np.sqrt(average_cmag_v1/2), 'k:', label='V1')\n",
    "ax.plot(eccen, np.sqrt(average_cmag_v2/2), 'r:', label='V2')\n",
    "ax.plot(eccen, np.sqrt(average_cmag_v3/2), 'm:', label='V3')\n",
    "ax.plot(eccen, np.sqrt(average_cmag_v4/2), 'g:', label='hV4')\n",
    "\n",
    "# Plotting the fitted lines for each visual area\n",
    "ax.plot(eccen, np.sqrt((popt1[0]/(eccen+popt1[1]))**2/2), 'k', label='V1 fitted line')\n",
    "ax.plot(eccen, np.sqrt((popt2[0]/(eccen+popt2[1]))**2/2), 'r', label='V2 fitted line')\n",
    "ax.plot(eccen, np.sqrt((popt3[0]/(eccen+popt3[1]))**2/2), 'm', label='V3 fitted line')\n",
    "ax.plot(eccen, np.sqrt((popt4[0]/(eccen+popt4[1]))**2/2), 'g', label='hV4 fitted line')\n",
    "\n",
    "# Plotting the confidence intervals for each visual area\n",
    "ax.fill_between(eccen, \n",
    "                 np.sqrt(confidence_interval_v1[0]/2),\n",
    "                 np.sqrt(confidence_interval_v1[1]/2),\n",
    "                 color='k', alpha=0.3)\n",
    "ax.fill_between(eccen, \n",
    "                 np.sqrt(confidence_interval_v2[0]/2),\n",
    "                 np.sqrt(confidence_interval_v2[1]/2),\n",
    "                 color='r', alpha=0.3)\n",
    "ax.fill_between(eccen, \n",
    "                 np.sqrt(confidence_interval_v3[0]/2),\n",
    "                 np.sqrt(confidence_interval_v3[1]/2),\n",
    "                 color='m', alpha=0.3)\n",
    "ax.fill_between(eccen, \n",
    "                 np.sqrt(confidence_interval_v4[0]/2),\n",
    "                 np.sqrt(confidence_interval_v4[1]/2),\n",
    "                 color='g', alpha=0.3)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Eccentricity (deg)\")\n",
    "ax.set_ylabel(\"Radial Cortical Magnification (mm/deg)\")\n",
    "ax.set_title(\"Average Radial Cortical Magnification for V1, V2, V3, hV4\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8980017",
   "metadata": {},
   "source": [
    "### using bootstrapped fits to get cortical crowding distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dfeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to store bootstrapped CCD values for each visual area\n",
    "bootstrapped_ccd_1 = []\n",
    "bootstrapped_ccd_2 = []\n",
    "bootstrapped_ccd_3 = []\n",
    "bootstrapped_ccd_4 = []\n",
    "\n",
    "# \"bootstrapped\" here refers to crowding distance result\n",
    "for i in range(len(bootstrapped)):\n",
    "    # Calculate bootstrapped CCD for visual area 1\n",
    "    ccd_v1 = bootstrapped[i] * np.sqrt(bootstrapped_v1[i] / 2)\n",
    "    bootstrapped_ccd_1.append(ccd_v1)\n",
    "    \n",
    "    # Calculate bootstrapped CCD for visual area 2\n",
    "    ccd_v2 = bootstrapped[i] * np.sqrt(bootstrapped_v2[i] / 2)\n",
    "    bootstrapped_ccd_2.append(ccd_v2)\n",
    "    \n",
    "    # Calculate bootstrapped CCD for visual area 3\n",
    "    ccd_v3 = bootstrapped[i] * np.sqrt(bootstrapped_v3[i] / 2)\n",
    "    bootstrapped_ccd_3.append(ccd_v3)\n",
    "    \n",
    "    # Calculate bootstrapped CCD for visual area 4\n",
    "    ccd_v4 = bootstrapped[i] * np.sqrt(bootstrapped_v4[i] / 2)\n",
    "    bootstrapped_ccd_4.append(ccd_v4)\n",
    "\n",
    "# Convert lists to arrays\n",
    "bootstrapped_ccd_1 = np.array(bootstrapped_ccd_1)\n",
    "bootstrapped_ccd_2 = np.array(bootstrapped_ccd_2)\n",
    "bootstrapped_ccd_3 = np.array(bootstrapped_ccd_3)\n",
    "bootstrapped_ccd_4 = np.array(bootstrapped_ccd_4)\n",
    "\n",
    "# Calculate the mean of bootstrapped CCD values for each visual area\n",
    "xx1 = np.mean(bootstrapped_ccd_1, axis=0)\n",
    "xx2 = np.mean(bootstrapped_ccd_2, axis=0)\n",
    "xx3 = np.mean(bootstrapped_ccd_3, axis=0)\n",
    "xx4 = np.mean(bootstrapped_ccd_4, axis=0)\n",
    "\n",
    "# Calculate the confidence interval for bootstrapped CCD values for each visual area\n",
    "confidence_interval_ccd_1 = np.percentile(bootstrapped_ccd_1,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_2 = np.percentile(bootstrapped_ccd_2,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_3 = np.percentile(bootstrapped_ccd_3,  [16, 84], axis=0)\n",
    "confidence_interval_ccd_4 = np.percentile(bootstrapped_ccd_4,  [16, 84], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74cf81",
   "metadata": {},
   "source": [
    "### coefficient of variation for cortical crowding distance at each area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ff518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coefficient of variation for ccd_1\n",
    "mean_ccd_1 = np.mean(xx1)\n",
    "std_ccd_1 = np.std(xx1)\n",
    "cv_ccd_1 = std_ccd_1 / mean_ccd_1\n",
    "rounded_cv_ccd_1 = round(cv_ccd_1, 2)\n",
    "\n",
    "print(\"Coefficient of Variation (CCD 1):\", rounded_cv_ccd_1)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_2\n",
    "mean_ccd_2 = np.mean(xx2)\n",
    "std_ccd_2 = np.std(xx2)\n",
    "cv_ccd_2 = std_ccd_2 / mean_ccd_2\n",
    "rounded_cv_ccd_2 = round(cv_ccd_2, 2)\n",
    "print(\"Coefficient of Variation (CCD 2):\", rounded_cv_ccd_2)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_3\n",
    "mean_ccd_3 = np.mean(xx3)\n",
    "std_ccd_3 = np.std(xx3)\n",
    "cv_ccd_3 = std_ccd_3 / mean_ccd_3\n",
    "rounded_cv_ccd_3 = round(cv_ccd_3, 2)\n",
    "print(\"Coefficient of Variation (CCD 3):\", rounded_cv_ccd_3)\n",
    "\n",
    "# Calculate the coefficient of variation for ccd_4\n",
    "mean_ccd_4 = np.mean(xx4)\n",
    "std_ccd_4 = np.std(xx4)\n",
    "cv_ccd_4 = std_ccd_4 / mean_ccd_4\n",
    "rounded_cv_ccd_4 = round(cv_ccd_4, 2)\n",
    "print(\"Coefficient of Variation (CCD 4):\", rounded_cv_ccd_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_cv(data, num_samples):\n",
    "    \"\"\"\n",
    "    Perform bootstrapping to compute the coefficient of variation (CV).\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy.ndarray)\n",
    "        num_samples (int): Number of bootstrap samples to generate.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array containing the bootstrapped CV values.\n",
    "    \"\"\"\n",
    "    bootstrapped_cv = []\n",
    "    n = len(data)\n",
    "    for _ in range(num_samples):\n",
    "        sample_indices = np.random.choice(range(n), size=n, replace=True)\n",
    "        bootstrapped_sample = data[sample_indices]\n",
    "        mean_sample = np.mean(bootstrapped_sample)\n",
    "        std_sample = np.std(bootstrapped_sample)\n",
    "        cv_sample = std_sample / mean_sample\n",
    "        bootstrapped_cv.append(cv_sample)\n",
    "    return np.array(bootstrapped_cv)\n",
    "\n",
    "# Perform bootstrap on CCD 1\n",
    "bootstrapped_cv_1 = bootstrap_cv(xx1, num_samples=1000)\n",
    "ci_1 = np.percentile(bootstrapped_cv_1, [2.5, 97.5])\n",
    "\n",
    "# Perform bootstrap on CCD 2\n",
    "bootstrapped_cv_2 = bootstrap_cv(xx2, num_samples=1000)\n",
    "ci_2 = np.percentile(bootstrapped_cv_2, [2.5, 97.5])\n",
    "\n",
    "# Perform bootstrap on CCD 3\n",
    "bootstrapped_cv_3 = bootstrap_cv(xx3, num_samples=1000)\n",
    "ci_3 = np.percentile(bootstrapped_cv_3, [2.5, 97.5])\n",
    "\n",
    "# Perform bootstrap on CCD 4\n",
    "bootstrapped_cv_4 = bootstrap_cv(xx4, num_samples=1000)\n",
    "ci_4 = np.percentile(bootstrapped_cv_4, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a62301",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ccd_1 = bootstrapped_cv_1.mean()\n",
    "cv_ccd_2 = bootstrapped_cv_2.mean()\n",
    "cv_ccd_3 = bootstrapped_cv_3.mean()\n",
    "cv_ccd_4 = bootstrapped_cv_4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47861a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of mean CV in each area\n",
    "cv_ccd_values = [cv_ccd_1, cv_ccd_2, cv_ccd_3, cv_ccd_4]\n",
    "ccd_labels = ['V1', 'V2', 'V3', 'V4']\n",
    "\n",
    "# a list of CI in each area\n",
    "cv_ci_list = [(ci_1[0], ci_1[1]), (ci_2[0], ci_2[1]), (ci_3[0], ci_3[1]),(ci_4[0], ci_4[1])]\n",
    "\n",
    "# lower and upper bounds of CI\n",
    "lower_bound = [ci[0] for ci in cv_ci_list]\n",
    "upper_bound = [ci[1] for ci in cv_ci_list]\n",
    "\n",
    "yerr = [[cv_ccd_values[i] - lower_bound[i] for i in range(len(cv_ccd_values))],\n",
    "        [upper_bound[i] - cv_ccd_values[i] for i in range(len(cv_ccd_values))]]\n",
    "\n",
    "# bar plot with error bars\n",
    "plt.bar(ccd_labels, cv_ccd_values, yerr=yerr, capsize=5, color=['grey', 'red', 'magenta', 'green'])\n",
    "\n",
    "plt.xlabel('Visual Areas')\n",
    "plt.ylabel('Coefficient of Variation')\n",
    "plt.title('Coefficient of Variation for Cortical Crowding Distance')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cortical crowding distance vs eccen\n",
    "x = np.linspace(0.5, 10, 1000)\n",
    "plt.plot(x, xx1, label='Cortical crowding distance in V1', color='black')\n",
    "plt.plot(x, xx2, label='Cortical crowding distance in V2', color='red')\n",
    "plt.plot(x, xx3, label='Cortical crowding distance in V3', color='magenta')\n",
    "plt.plot(x, xx4, label='Cortical crowding distance in hV4', color='green')\n",
    "\n",
    "# Confidence intervals\n",
    "plt.fill_between(x, confidence_interval_ccd_1[0], confidence_interval_ccd_1[1], color='black', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_2[0], confidence_interval_ccd_2[1], color='red', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_3[0], confidence_interval_ccd_3[1], color='magenta', alpha=0.3)\n",
    "plt.fill_between(x, confidence_interval_ccd_4[0], confidence_interval_ccd_4[1], color='green', alpha=0.3)\n",
    "\n",
    "plt.xlabel('Eccentricity (deg)')\n",
    "plt.ylabel('Cortical Crowding Distance (mm)')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb02620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check quality of fits\n",
    "# (fig, axs) = plt.subplots(4, 2, figsize=(7, 7), dpi=288, sharex=True, sharey=True)\n",
    "\n",
    "# for i, lbl in enumerate([1, 2, 3, 4]):\n",
    "#     for j, hemi in enumerate(['lh', 'rh']):\n",
    "#         ax = axs[i, j]\n",
    "#         hfit_row = avg_ab[(avg_ab['label'] == lbl) & (avg_ab['h'] == hemi)]\n",
    "#         a = hfit_row['a'].values[0]\n",
    "#         b = hfit_row['b'].values[0]\n",
    "\n",
    "#         (ecc, srf) = cmag_basics(sid, hemi, lbl)\n",
    "#         ii = np.argsort(ecc)\n",
    "#         ecc = ecc[ii]\n",
    "#         cum_area = np.cumsum(srf[ii])\n",
    "\n",
    "#         cumarea_fit = cc.cmag.HH91_integral(ecc, a, b)\n",
    "#         cumarea_fit = np.interp(std_ecc, ecc, cumarea_fit)\n",
    "\n",
    "#         diff_mtx = diffs[hemi][lbl - 1]\n",
    "#         ii = np.isfinite(diff_mtx)\n",
    "#         diff_mtx[ii] = np.abs(diff_mtx[ii])\n",
    "#         diff_med = np.nanmedian(diff_mtx, axis=0)\n",
    "#         diff_95 = np.nanpercentile(diff_mtx, 95, axis=0)\n",
    "\n",
    "#         ax.plot(std_ecc, cumarea_fit/100, label=\"H&H Model Fit\", color='blue') \n",
    "#         ax.fill_between(std_ecc, (cumarea_fit - diff_med)/100, (cumarea_fit + diff_med)/100, color='0.5', alpha=0.7, label='Median Error')\n",
    "#         ax.fill_between(std_ecc, (cumarea_fit - diff_95)/100, (cumarea_fit + diff_95)/100, color='0.3', alpha=0.3, label='95% Error')\n",
    "\n",
    "#         axs[3,0].set_xlabel('Eccentricity [degree]')\n",
    "#         axs[3,1].set_xlabel('Eccentricity [degree]')\n",
    "#         ax.set_ylabel(r'Surface Area [cm$^2$]')\n",
    "#         ax.spines['top'].set_visible(False)\n",
    "#         ax.spines['right'].set_visible(False)\n",
    "\n",
    "#         axs[0, 1].legend(fontsize=10)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5b8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8f8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Jupyter Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
